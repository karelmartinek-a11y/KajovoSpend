diff --git a/README.md b/README.md
index 452774e..f8a2c12 100644
--- a/README.md
+++ b/README.md
@@ -1,86 +1,65 @@
-# KájovoSpend
-
-Desktopová aplikace pro evidenci a kategorizaci dokladů (faktury, účtenky, daňové doklady, stvrzenky) s lokální background „službou“, která sleduje vstupní adresář a automaticky zpracovává přidané soubory do lokální SQLite databáze.
-
-## Funkce (aktuální implementace)
-
-- GUI (PySide6): záhlaví s tlačítky STAV / RUN / STOP / RESTART / EXIT, karty podle zadání.
-- Služba: watchdog + periodické skenování, fronta v DB, paralelizace přes worker pool.
-- Idempotence: deduplikace podle SHA256 (duplicitní soubory se přesunou do OUTPUT/DUPLICITY).
-- OCR varianta B: RapidOCR (offline) + PDF render přes PDFium (pypdfium2). Pokud PDF obsahuje textovou vrstvu, použije se primárně ta.
-- ARES: dotažení dodavatele podle IČO (při neúspěchu jde doklad do kontroly).
-- Režim „raději do karantény“: při nízké jistotě vytěžení se soubor přesune do OUTPUT/KARANTENA a objeví se v kartě NEROZPOZNANÉ pro ruční doplnění.
-- Fulltext (FTS5) pro hledání v dokladech i položkách.
-- Exporty CSV/XLSX ze seznamu dokladů.
-
-## Požadavky
-
-- Windows 10/11
-- Python 3.11 - 3.13 (Python 3.14 zatím ne: chybí Windows wheels pro Pillow a onnxruntime, které vyžaduje RapidOCR)
-
-## Instalace
-
-```powershell
-cd KajovoSpend
-python -m venv .venv
-.\.venv\Scripts\activate
-pip install -r requirements.txt
-```
-
-1) Vytvoř konfiguraci:
-
-```powershell
-copy config.example.yaml config.yaml
-```
-
-2) Uprav v `config.yaml` cesty `paths.input_dir` a `paths.output_dir`.
-
-3) Inicializace DB proběhne automaticky při startu GUI nebo služby.
-
-## Spuštění
-
-GUI:
-
-```powershell
-.\.venv\Scripts\python.exe app_gui.py
-```
-
-Služba (ručně v konzoli):
-
-```powershell
-.\.venv\Scripts\python.exe service_main.py --config config.yaml
-```
-
-## Instalace služby na Windows (Task Scheduler)
-
-V `scripts/` jsou připravené PowerShell skripty:
-
-- `install_service_task.ps1` – vytvoří Scheduled Task, který spouští službu při přihlášení uživatele.
-- `uninstall_service_task.ps1` – odebere úlohu.
-
-Příklad:
-
-```powershell
-powershell -ExecutionPolicy Bypass -File scripts\install_service_task.ps1 -ProjectDir "C:\\path\\to\\KajovoSpend"
-```
-
-GUI tlačítko RUN/STOP/RESTART pracuje primárně přes lokální RPC (127.0.0.1:8765). Pokud služba běží jako Scheduled Task, STOP ji ukončí korektně a Task ji znovu spustí při dalším startu úlohy.
-
-## OCR modely (volitelné „připnutí“)
-
-RapidOCR funguje i bez ručního stahování modelů. Pokud chceš držet modely explicitně lokálně, použij:
-
-```powershell
-.\.venv\Scripts\python.exe scripts\download_ocr_models.py --models-dir "%LOCALAPPDATA%\\KajovoSpend\\models\\rapidocr"
-```
-
-Pozn.: odkazy na modely se mohou časem změnit; skript je koncipovaný jako helper (případně doplň URL podle zvoleného modelového balíku).
-
-## Databáze
-
-SQLite je v `%LOCALAPPDATA%\\KajovoSpend\\kajovospend.sqlite` (pokud v configu nepřepíšeš).
-
-## Logy
-
-`%LOCALAPPDATA%\\KajovoSpend\\logs\\kajovospend_service.log` a `kajovospend_gui.log`.
-
+# KájovoSpend
+
+Desktopová aplikace pro evidenci a kategorizaci dokladů (faktury, účtenky, daňové doklady, stvrzenky). Zpracování dokladů se spouští přímo z GUI na kartě RUN tlačítkem „IMPORTUJ“ (žádná externí služba / Scheduled Task).
+
+## Funkce (aktuální implementace)
+
+- GUI (PySide6): karta RUN (IMPORT + status + přehledné statistiky), ÚČTY, POLOŽKY, NEROZPOZNANÉ, DODAVATELÉ, PROVOZNÍ PANEL, PODEZŘELÉ, VÝDAJE.
+- Deduplikace podle SHA256 (duplicitní soubory se přesunou do OUTPUT/DUPLICITY).
+- OCR varianta B: RapidOCR (offline) + PDF render přes PDFium (pypdfium2). Pokud PDF obsahuje textovou vrstvu, použije se primárně ta.
+- ARES: dotažení dodavatele podle IČO (při neúspěchu jde doklad do kontroly).
+- Režim „raději do karantény“: při nízké jistotě vytěžení se soubor přesune do OUTPUT/KARANTENA a objeví se v kartě NEROZPOZNANÉ pro ruční doplnění.
+- Fulltext (FTS5) pro hledání v dokladech i položkách.
+- Exporty CSV/XLSX ze seznamu dokladů.
+
+## Požadavky
+
+- Windows 10/11
+- Python 3.11 - 3.13
+
+## Instalace
+
+```powershell
+cd KajovoSpend
+python -m venv .venv
+.\.venv\Scripts\activate
+pip install -r requirements.txt
+```
+
+1) Vytvoř konfiguraci:
+
+```powershell
+copy config.example.yaml config.yaml
+```
+
+2) Uprav v `config.yaml` cesty `paths.input_dir` a `paths.output_dir`.
+
+3) Inicializace DB proběhne automaticky při startu GUI.
+
+## Spuštění
+
+```powershell
+.\.venv\Scripts\python.exe app_gui.py
+```
+
+## Práce s importem
+
+1) Nakopíruj soubory (PDF/obrázky) do adresáře `paths.input_dir`.
+2) Otevři kartu RUN a klikni na „IMPORTUJ“.
+3) Doklady se po zpracování přesunou do `paths.output_dir` (případně do podadresářů DUPLICITY / KARANTENA).
+
+## OCR modely (volitelné „připnutí“)
+
+RapidOCR funguje i bez ručního stahování modelů. Pokud chceš držet modely explicitně lokálně, použij:
+
+```powershell
+.\.venv\Scripts\python.exe scripts\download_ocr_models.py --models-dir "%LOCALAPPDATA%\KajovoSpend\models\rapidocr"
+```
+
+## Databáze
+
+SQLite je v `%LOCALAPPDATA%\\KajovoSpend\\kajovospend.sqlite` (pokud v configu nepřepíšeš).
+
+## Logy
+
+`%LOCALAPPDATA%\\KajovoSpend\\logs\\kajovospend_gui.log`.
diff --git a/__pycache__/app_gui.cpython-311.pyc b/__pycache__/app_gui.cpython-311.pyc
new file mode 100644
index 0000000..0818ec7
Binary files /dev/null and b/__pycache__/app_gui.cpython-311.pyc differ
diff --git a/__pycache__/kajovospend_shared.cpython-311.pyc b/__pycache__/kajovospend_shared.cpython-311.pyc
new file mode 100644
index 0000000..d2aa1f2
Binary files /dev/null and b/__pycache__/kajovospend_shared.cpython-311.pyc differ
diff --git a/__pycache__/service_main.cpython-311.pyc b/__pycache__/service_main.cpython-311.pyc
new file mode 100644
index 0000000..dbba69c
Binary files /dev/null and b/__pycache__/service_main.cpython-311.pyc differ
diff --git a/scripts/__pycache__/download_ocr_models.cpython-311.pyc b/scripts/__pycache__/download_ocr_models.cpython-311.pyc
new file mode 100644
index 0000000..8c5aaf8
Binary files /dev/null and b/scripts/__pycache__/download_ocr_models.cpython-311.pyc differ
diff --git a/src/kajovospend/__pycache__/__init__.cpython-311.pyc b/src/kajovospend/__pycache__/__init__.cpython-311.pyc
new file mode 100644
index 0000000..d3aa0a3
Binary files /dev/null and b/src/kajovospend/__pycache__/__init__.cpython-311.pyc differ
diff --git a/src/kajovospend/db/__pycache__/__init__.cpython-311.pyc b/src/kajovospend/db/__pycache__/__init__.cpython-311.pyc
new file mode 100644
index 0000000..850bed0
Binary files /dev/null and b/src/kajovospend/db/__pycache__/__init__.cpython-311.pyc differ
diff --git a/src/kajovospend/db/__pycache__/base.cpython-311.pyc b/src/kajovospend/db/__pycache__/base.cpython-311.pyc
new file mode 100644
index 0000000..2183a10
Binary files /dev/null and b/src/kajovospend/db/__pycache__/base.cpython-311.pyc differ
diff --git a/src/kajovospend/db/__pycache__/migrate.cpython-311.pyc b/src/kajovospend/db/__pycache__/migrate.cpython-311.pyc
new file mode 100644
index 0000000..f146b6d
Binary files /dev/null and b/src/kajovospend/db/__pycache__/migrate.cpython-311.pyc differ
diff --git a/src/kajovospend/db/__pycache__/models.cpython-311.pyc b/src/kajovospend/db/__pycache__/models.cpython-311.pyc
new file mode 100644
index 0000000..dca9cba
Binary files /dev/null and b/src/kajovospend/db/__pycache__/models.cpython-311.pyc differ
diff --git a/src/kajovospend/db/__pycache__/queries.cpython-311.pyc b/src/kajovospend/db/__pycache__/queries.cpython-311.pyc
new file mode 100644
index 0000000..18a021a
Binary files /dev/null and b/src/kajovospend/db/__pycache__/queries.cpython-311.pyc differ
diff --git a/src/kajovospend/db/__pycache__/session.cpython-311.pyc b/src/kajovospend/db/__pycache__/session.cpython-311.pyc
new file mode 100644
index 0000000..62c6614
Binary files /dev/null and b/src/kajovospend/db/__pycache__/session.cpython-311.pyc differ
diff --git a/src/kajovospend/extract/__pycache__/__init__.cpython-311.pyc b/src/kajovospend/extract/__pycache__/__init__.cpython-311.pyc
new file mode 100644
index 0000000..ad8310b
Binary files /dev/null and b/src/kajovospend/extract/__pycache__/__init__.cpython-311.pyc differ
diff --git a/src/kajovospend/extract/__pycache__/parser.cpython-311.pyc b/src/kajovospend/extract/__pycache__/parser.cpython-311.pyc
new file mode 100644
index 0000000..d013811
Binary files /dev/null and b/src/kajovospend/extract/__pycache__/parser.cpython-311.pyc differ
diff --git a/src/kajovospend/extract/parser.py b/src/kajovospend/extract/parser.py
index 1f86589..e723545 100644
--- a/src/kajovospend/extract/parser.py
+++ b/src/kajovospend/extract/parser.py
@@ -1,452 +1,523 @@
-from __future__ import annotations
-
-import re
-import datetime as dt
-from dataclasses import dataclass
-from typing import List, Optional, Tuple, Dict, Iterable
-
-from dateutil import parser as dtparser
-
-
-@dataclass
-class Extracted:
-    supplier_ico: Optional[str]
-    doc_number: Optional[str]
-    bank_account: Optional[str]
-    issue_date: Optional[dt.date]
-    total_with_vat: Optional[float]
-    currency: str
-    items: List[dict]
-    confidence: float
-    requires_review: bool
-    review_reasons: List[str]
-    full_text: str
-
-
-_amount_re = re.compile(r"(-?\d+[\d\s]*[.,]\d{2})")
-_ICO_CTX_RE = re.compile(r"\b(IČO|ICO|IČ)\b", re.IGNORECASE)
-_ICO_DIGITS_RE = re.compile(r"\D+")
-
-# Časté mapování DPH písmenem na účtenkách (není univerzální, ale pomáhá u velké části CZ retail).
-_VAT_LETTER_MAP: Dict[str, float] = {"A": 21.0, "B": 15.0, "C": 10.0}
-
-# Položky typu „zaokrouhlení“ (často samostatný řádek na účtence)
-_ROUNDING_RE = re.compile(
-    r"\b(zaokrouhlen[ií]|zaokr\.?)(?:\s*[: ]\s*)?(?P<amount>-?\d+[\d\s]*[.,]\d{2})\b",
-    re.IGNORECASE,
-)
-
-
-def _extract_rounding_items(text: str) -> List[dict]:
-    items: List[dict] = []
-    if not text:
-        return items
-    for ln in text.splitlines():
-        m = _ROUNDING_RE.search(ln)
-        if not m:
-            continue
-        try:
-            amt = _norm_amount(m.group("amount"))
-        except Exception:
-            continue
-        # Zaokrouhlení je samostatná položka; DPH neaplikujeme.
-        items.append(
-            {
-                "name": "Zaokrouhlení",
-                "quantity": 1.0,
-                "unit_price": amt,   # kanonicky: bez DPH; u zaokrouhlení je to stejné
-                "vat_rate": 0.0,
-                "line_total": amt,   # včetně DPH; u zaokrouhlení je to stejné
-            }
-        )
-    return items
-
-
-def _iter_non_rounding(items: Iterable[dict]) -> Iterable[dict]:
-    for it in items:
-        name = str(it.get("name") or "").strip().lower()
-        if "zaokrouhl" in name or name in {"zaokr", "zaokr."}:
-            continue
-        yield it
-
-
-def _canonicalize_items_to_unit_net_and_line_gross(
-    items: List[dict],
-    total_with_vat: Optional[float],
-    reasons: List[str],
-    *,
-    rel_tol: float = 0.03,
-    abs_tol: float = 2.0,
-) -> bool:
-    """
-    Kanonická reprezentace položek pro výpočty a DB:
-      - unit_price = cena za 1 jednotku bez DPH
-      - line_total = řádková cena včetně DPH
-
-    Vrací True, pokud součet položek sedí na total_with_vat v toleranci.
-    """
-    if not items:
-        return False
-
-    # nejdřív doplň chybějící line_total tam, kde to jde
-    _normalize_items(items, reasons)
-
-    # u mnoha dokladů jsou částky v položkách net (bez DPH), ale total je gross
-    # => vyzkoušíme 2 režimy a vybereme ten s menší odchylkou.
-    def _sum_for_mode(mode: str) -> float:
-        s = 0.0
-        for it in items:
-            q = _f(it.get("quantity"), 1.0)
-            vr = _f(it.get("vat_rate"), 0.0)
-            lt = _f(it.get("line_total"), 0.0)
-            up = it.get("unit_price")
-            upf = None if up is None else _f(up, 0.0)
-            base = lt if lt != 0.0 else (q * (upf or 0.0))
-            if mode == "gross":
-                s += base
-            else:
-                # net -> gross
-                s += base * (1.0 + (vr / 100.0)) if vr > 0 else base
-        return float(s)
-
-    chosen = "gross"
-    if total_with_vat is not None and total_with_vat != 0.0:
-        sum_g = _sum_for_mode("gross")
-        sum_n = _sum_for_mode("net")
-        diff_g = abs(sum_g - total_with_vat)
-        diff_n = abs(sum_n - total_with_vat)
-        chosen = "net" if diff_n + 1e-9 < diff_g else "gross"
-
-    # Kanonizace do (unit_net, line_gross)
-    for it in items:
-        name = str(it.get("name") or "").strip()
-        q = _f(it.get("quantity"), 1.0)
-        vr = _f(it.get("vat_rate"), 0.0)
-        lt = _f(it.get("line_total"), 0.0)
-        up = it.get("unit_price")
-        upf = None if up is None else _f(up, 0.0)
-        if q == 0.0:
-            q = 1.0
-            it["quantity"] = 1.0
-            reasons.append("oprava položky: quantity=0 nahrazeno 1")
-
-        # zaokrouhlení a podobné položky bereme jako gross==net
-        if "zaokrouhl" in name.lower():
-            it["vat_rate"] = 0.0
-            it["unit_price"] = round(lt if lt != 0.0 else (upf or 0.0), 2)
-            it["line_total"] = round(lt if lt != 0.0 else (upf or 0.0), 2)
-            continue
-
-        base = lt if lt != 0.0 else (q * (upf or 0.0))
-        if chosen == "net":
-            line_gross = base * (1.0 + (vr / 100.0)) if vr > 0 else base
-            unit_net = (base / q) if q else 0.0
-        else:
-            line_gross = base
-            unit_net = (base / q) / (1.0 + (vr / 100.0)) if (q and vr > 0) else ((base / q) if q else 0.0)
-
-        # finální zápis
-        it["unit_price"] = round(unit_net, 4)  # 4 desetinná místa zlepší následné přepočty
-        it["line_total"] = round(line_gross, 2)
-
-    # Ověření: podle unit_net * (1+vat) * qty musí sedět line_total a total
-    sum_calc = 0.0
-    for it in items:
-        q = _f(it.get("quantity"), 1.0)
-        vr = _f(it.get("vat_rate"), 0.0)
-        upn = _f(it.get("unit_price"), 0.0)
-        calc = (upn * (1.0 + vr / 100.0) * q) if vr > 0 else (upn * q)
-        calc = round(calc, 2)
-        lt = _f(it.get("line_total"), 0.0)
-        # pokud se liší o víc než haléř, přepiš na konzistentní výsledek
-        if abs(calc - lt) > 0.02:
-            it["line_total"] = calc
-            reasons.append("oprava položky: line_total přepočteno z unit_price_net*DPH*qty")
-        sum_calc += _f(it.get("line_total"), 0.0)
-
-    if total_with_vat is None or total_with_vat == 0.0:
-        return False
-    diff = abs(sum_calc - total_with_vat)
-    rel = diff / max(abs(total_with_vat), 1e-9)
-    return (diff <= abs_tol) or (rel <= rel_tol)
-
-
-def _norm_amount(s: str) -> float:
-    s = s.replace("\xa0", " ")
-    s = s.strip()
-    s = s.replace(" ", "")
-    s = s.replace(",", ".")
-    return float(s)
-
-def _f(v, default: float = 0.0) -> float:
-    if v is None:
-        return float(default)
-    if isinstance(v, (int, float)):
-        return float(v)
-    try:
-        s = str(v).strip().replace("\xa0", " ").replace(" ", "").replace(",", ".")
-        if not s:
-            return float(default)
-        return float(s)
-    except Exception:
-        return float(default)
-
-def _normalize_items(items: List[dict], reasons: List[str]) -> None:
-    """
-    Sjednotí položky do deterministické podoby pro výpočty:
-    - když chybí line_total a máme qty+unit_price -> dopočítá
-    - když line_total zjevně obsahuje jednotkovou cenu (qty>1 a line_total≈unit_price) -> opraví na qty*unit_price
-    """
-    for it in items:
-        q = _f(it.get("quantity"), 1.0)
-        up = it.get("unit_price")
-        upf = None if up is None else _f(up, 0.0)
-        lt = _f(it.get("line_total"), 0.0)
-        # dopočet, když line_total chybí
-        if (lt <= 0.0) and (upf is not None) and (q > 0):
-            it["line_total"] = round(q * upf, 2)
-            continue
-        # častý OCR/format case: line_total je ve skutečnosti jednotková cena
-        if (upf is not None) and (q > 1.0) and (lt > 0.0):
-            if abs(lt - upf) <= 0.02 and abs((q * upf) - lt) > 0.05:
-                it["line_total"] = round(q * upf, 2)
-                reasons.append("oprava položky: řádková cena dopočtena z qty*unit_price")
-
-
-def _safe_float(s: str) -> float:
-    return float(str(s).strip().replace("\xa0", " ").replace(" ", "").replace(",", "."))
-
-
-def _find_first(patterns: list[re.Pattern], text: str) -> Optional[str]:
-    for p in patterns:
-        m = p.search(text)
-        if m:
-            return m.group(1).strip()
-    return None
-
-
-def _normalize_ico_soft(ico: str | None) -> str | None:
-    if ico is None:
-        return None
-    raw = str(ico).strip()
-    if not raw:
-        return None
-    digits = _ICO_DIGITS_RE.sub("", raw)
-    if not digits:
-        return None
-    if len(digits) > 8:
-        # když OCR slije více čísel – raději vrátit původní digit-only; verifikace ARES stejně rozhodne
-        return digits
-    return digits.zfill(8)
-
-
-def _parse_date(s: str) -> Optional[dt.date]:
-    s = s.strip()
-    try:
-        # support dd.mm.yyyy and dd/mm/yyyy and ISO
-        d = dtparser.parse(s, dayfirst=True).date()
-        return d
-    except Exception:
-        return None
-
-
-def extract_from_text(text: str) -> Extracted:
-    raw = text or ""
-    t = raw
-
-    # IČO: dříve se bralo libovolné 8-číslí => často sebralo VS/číslo dokladu.
-    # Teď vyžadujeme kontext (IČO/ICO/IČ) a normalizujeme.
-    ico = _find_first(
-        [
-            re.compile(r"\bIČO\s*[: ]\s*([0-9][0-9\s-]{6,}[0-9])\b", re.IGNORECASE),
-            re.compile(r"\bICO\s*[: ]\s*([0-9][0-9\s-]{6,}[0-9])\b", re.IGNORECASE),
-            re.compile(r"\bIČ\s*[: ]\s*([0-9][0-9\s-]{6,}[0-9])\b", re.IGNORECASE),
-        ],
-        t,
-    )
-    ico = _normalize_ico_soft(ico)
-
-    doc_no = _find_first([
-        re.compile(r"Č[ií]slo\s+faktury\s*[: ]\s*([\w-]+)", re.IGNORECASE),
-        re.compile(r"DAŇOVÝ\s+DOKLAD\s+č\.?\s*([\w-]+)", re.IGNORECASE),
-        re.compile(r"Faktura\s*-?\s*daňový\s+doklad\s+č\.?\s*([\w-]+)", re.IGNORECASE),
-        re.compile(r"\bVS\s*[: ]\s*(\d{3,})\b", re.IGNORECASE),
-    ], t)
-
-    bank_account = _find_first([
-        re.compile(r"\bIBAN\s*[: ]\s*([A-Z]{2}\d{2}[A-Z0-9]{10,})\b"),
-        re.compile(r"\bÚčet\s*[: ]\s*(\d{6,}-?\d{2,}/\d{4})\b", re.IGNORECASE),
-        re.compile(r"\b(\d{6,}-?\d{2,})\s*/\s*(\d{4})\b"),
-    ], t)
-    if bank_account and " " in bank_account:
-        bank_account = bank_account.replace(" ", "")
-
-    date_s = _find_first([
-        re.compile(r"Datum\s+vystaven[ií]\s*[: ]\s*([0-9]{1,2}[./][0-9]{1,2}[./][0-9]{2,4})", re.IGNORECASE),
-        re.compile(r"Datum\s*[: ]\s*([0-9]{1,2}[./][0-9]{1,2}[./][0-9]{2,4})", re.IGNORECASE),
-        re.compile(r"\b([0-9]{2}/[0-9]{2}/[0-9]{4})\b"),
-    ], t)
-    issue_date = _parse_date(date_s) if date_s else None
-
-    # currency
-    currency = "CZK" if re.search(r"\bCZK\b|Kč", t) else "EUR" if re.search(r"\bEUR\b", t) else "CZK"
-
-    # total
-    total_s = _find_first([
-        re.compile(r"CELKEM\s+K\s+ÚHRADĚ\s*\n?\s*([0-9\s]+[.,][0-9]{2})", re.IGNORECASE),
-        re.compile(r"Celkem\s+k\s+úhradě\s*[: ]\s*([0-9\s]+[.,][0-9]{2})", re.IGNORECASE),
-        re.compile(r"K\s+zaplacení\s+celkem\s+EUR\s*([0-9\s]+[.,][0-9]{2})", re.IGNORECASE),
-        re.compile(r"Cena\s+celkem\s*([0-9\s]+[.,][0-9]{2})", re.IGNORECASE),
-        re.compile(r"Koruna\s+česká\s+Kč\s*([0-9\s]+[.,][0-9]{2})", re.IGNORECASE),
-    ], t)
-
-    total = None
-    if total_s:
-        try:
-            total = _norm_amount(total_s)
-        except Exception:
-            total = None
-
-    items: List[dict] = []
-    # attempt parse tabular items (e.g., Rohlik PDF text)
-    # pattern: <name> <qty> ks <unit> Kč <vat%> % <...> <line_total> Kč
-    line_pat = re.compile(
-        r"^(?P<name>.+?)\s+(?P<qty>-?\d+(?:[.,]\d+)?)\s*(?:ks|x)?\s+(?P<unit>\d+[\s\d]*[.,]\d{2})\s*Kč\s+(?P<vat>\d{1,2})\s*%\s+.*?\s+(?P<total>-?\d+[\s\d]*[.,]\d{2})\s*Kč\s*$",
-        re.IGNORECASE
-    )
-
-    for ln in t.splitlines():
-        ln = ln.strip()
-        if not ln or len(ln) < 6:
-            continue
-        m = line_pat.match(ln)
-        if m:
-            try:
-                name = m.group("name").strip()
-                qty = _safe_float(m.group("qty"))
-                unit_price = _norm_amount(m.group("unit"))
-                vat = float(m.group("vat"))
-                line_total = _norm_amount(m.group("total"))
-                items.append({"name": name, "quantity": qty, "unit_price": unit_price, "vat_rate": vat, "line_total": line_total})
-            except Exception:
-                continue
-
-    # receipts (Albert): lines like "2 x 5,60 Kč 11,20"
-    if not items:
-        rec_pat = re.compile(r"^(?P<name>[A-ZÁČĎÉĚÍŇÓŘŠŤÚŮÝŽ0-9 .,'/-]{3,})\s*$")
-        qty_price_pat = re.compile(
-            r"^(?P<qty>\d+(?:[.,]\d+)?)\s*[xX]\s*(?P<unit>\d+[\s\d]*[.,]\d{2}).*?(?P<total>\d+[\s\d]*[.,]\d{2})\s*(?P<vat_letter>[A-Z])?\s*$"
-        )
-        pending_name: Optional[str] = None
-        for ln in t.splitlines():
-            ln = ln.strip()
-            if not ln:
-                continue
-            if pending_name is None:
-                if rec_pat.match(ln) and not re.search(r"(Celkem|DPH|Datum|Děkujeme|Kč|EUR|IBAN)", ln, re.IGNORECASE):
-                    pending_name = ln
-                continue
-            m2 = qty_price_pat.match(ln)
-            if m2:
-                try:
-                    qty = _safe_float(m2.group("qty"))
-                    unit_price = _norm_amount(m2.group("unit"))
-                    line_total = _norm_amount(m2.group("total"))
-                    vat_letter = (m2.group("vat_letter") or "").strip().upper()
-                    vat = _VAT_LETTER_MAP.get(vat_letter, 0.0)
-                    items.append({"name": pending_name, "quantity": qty, "unit_price": unit_price, "vat_rate": vat, "line_total": line_total})
-                except Exception:
-                    pass
-                pending_name = None
-            else:
-                pending_name = None
-
-    # zaokrouhlení (pokud existuje) přidáme jako samostatnou položku
-    items.extend(_extract_rounding_items(t))
-
-    # --- kontrola součtu položek vs. celkem ---
-    # Cíl: co nejvíc dokladů vyřešit offline, a na OpenAI posílat jen minimum.
-    reasons: List[str] = []
-    sum_ok = False
-    try:
-        sum_ok = _canonicalize_items_to_unit_net_and_line_gross(items, total, reasons)
-        if items and (total is not None) and not sum_ok:
-            reasons.append("nesedí součet položek vs. celkem")
-    except Exception:
-        if items and total is not None:
-            reasons.append("nelze ověřit součet položek")
-
-    # confidence heuristic
-    conf = 0.0
-    if ico:
-        conf += 0.25
-    else:
-        reasons.append("chybí IČO")
-    if doc_no:
-        conf += 0.15
-    else:
-        reasons.append("chybí číslo dokladu")
-    if issue_date:
-        conf += 0.15
-    else:
-        reasons.append("chybí datum")
-    if total is not None:
-        conf += 0.25
-    else:
-        reasons.append("chybí celková cena")
-    if items:
-        conf += 0.20
-    else:
-        reasons.append("chybí položky")
-
-    # Pokud máme explicitní problém se součtem, je to vždy NEROZPOZNANÉ (neprojde do OUT).
-    # „nízká jistota vytěžení“ ale přidáváme jen při nízké confidence, ne při součtových problémech.
-    requires_review = False
-    if conf < 0.75:
-        requires_review = True
-        reasons.append("nízká jistota vytěžení")
-    if items and (total is not None) and (not sum_ok):
-        requires_review = True
-
-    return Extracted(
-        supplier_ico=ico,
-        doc_number=doc_no,
-        bank_account=bank_account,
-        issue_date=issue_date,
-        total_with_vat=total,
-        currency=currency,
-        items=items,
-        confidence=min(conf, 1.0),
-        requires_review=requires_review,
-        review_reasons=reasons,
-        full_text=raw,
-    )
-
-
-def postprocess_items_for_db(
-    *,
-    items: List[dict],
-    total_with_vat: Optional[float],
-    reasons: Optional[List[str]] = None,
-) -> Tuple[bool, List[str]]:
-    """
-    Normalizuje položky do kanonického formátu používaného v DB a provede kontrolu součtu.
-
-    Použití:
-      - po offline extrakci je voláno implicitně v extract_from_text()
-      - po OpenAI fallbacku je potřeba volat znovu, protože OpenAI vrací položky v různém základu
-
-    Vrací (sum_ok, reasons).
-    """
-    rr: List[str] = list(reasons or [])
-    ok = False
-    try:
-        ok = _canonicalize_items_to_unit_net_and_line_gross(items, total_with_vat, rr)
-        if items and (total_with_vat is not None) and not ok:
-            rr.append("nesedí součet položek vs. celkem")
-    except Exception:
-        if items and (total_with_vat is not None):
-            rr.append("nelze ověřit součet položek")
-    # de-dup reasons (stabilní pořadí)
-    rr = list(dict.fromkeys(rr))
-    return ok, rr
+from __future__ import annotations
+
+import re
+import datetime as dt
+from dataclasses import dataclass
+from typing import List, Optional, Tuple, Dict, Iterable
+
+from dateutil import parser as dtparser
+
+
+@dataclass
+class Extracted:
+    supplier_ico: Optional[str]
+    doc_number: Optional[str]
+    bank_account: Optional[str]
+    issue_date: Optional[dt.date]
+    total_with_vat: Optional[float]
+    currency: str
+    items: List[dict]
+    confidence: float
+    requires_review: bool
+    review_reasons: List[str]
+    full_text: str
+
+
+_amount_re = re.compile(r"(-?\d+[\d\s]*[.,]\d{2})")
+_ICO_CTX_RE = re.compile(r"\b(IČO|ICO|IČ)\b", re.IGNORECASE)
+_ICO_DIGITS_RE = re.compile(r"\D+")
+
+# Časté mapování DPH písmenem na účtenkách (není univerzální, ale pomáhá u velké části CZ retail).
+_VAT_LETTER_MAP: Dict[str, float] = {"A": 21.0, "B": 15.0, "C": 10.0}
+
+# Položky typu „zaokrouhlení“ (často samostatný řádek na účtence)
+_ROUNDING_RE = re.compile(
+    r"\b(zaokrouhlen[ií]|zaokr\.?)(?:\s*[: ]\s*)?(?P<amount>-?\d+[\d\s]*[.,]\d{2})\b",
+    re.IGNORECASE,
+)
+
+
+def _extract_rounding_items(text: str) -> List[dict]:
+    items: List[dict] = []
+    if not text:
+        return items
+    for ln in text.splitlines():
+        m = _ROUNDING_RE.search(ln)
+        if not m:
+            continue
+        try:
+            amt = _norm_amount(m.group("amount"))
+        except Exception:
+            continue
+        # Zaokrouhlení je samostatná položka; DPH neaplikujeme.
+        items.append(
+            {
+                "name": "Zaokrouhlení",
+                "quantity": 1.0,
+                "unit_price": amt,   # kanonicky: bez DPH; u zaokrouhlení je to stejné
+                "vat_rate": 0.0,
+                "line_total": amt,   # včetně DPH; u zaokrouhlení je to stejné
+            }
+        )
+    return items
+
+
+def _iter_non_rounding(items: Iterable[dict]) -> Iterable[dict]:
+    for it in items:
+        name = str(it.get("name") or "").strip().lower()
+        if "zaokrouhl" in name or name in {"zaokr", "zaokr."}:
+            continue
+        yield it
+
+
+def _canonicalize_items_to_unit_net_and_line_gross(
+    items: List[dict],
+    total_with_vat: Optional[float],
+    reasons: List[str],
+    *,
+    rel_tol: float = 0.03,
+    abs_tol: float = 2.0,
+) -> bool:
+    """
+    Kanonická reprezentace položek pro výpočty a DB:
+      - unit_price = cena za 1 jednotku bez DPH
+      - line_total = řádková cena včetně DPH
+
+    Vrací True, pokud součet položek sedí na total_with_vat v toleranci.
+    """
+    if not items:
+        return False
+
+    # nejdřív doplň chybějící line_total tam, kde to jde
+    _normalize_items(items, reasons)
+
+    # u mnoha dokladů jsou částky v položkách net (bez DPH), ale total je gross
+    # => vyzkoušíme 2 režimy a vybereme ten s menší odchylkou.
+    def _sum_for_mode(mode: str) -> float:
+        s = 0.0
+        for it in items:
+            q = _f(it.get("quantity"), 1.0)
+            vr = _f(it.get("vat_rate"), 0.0)
+            lt = _f(it.get("line_total"), 0.0)
+            up = it.get("unit_price")
+            upf = None if up is None else _f(up, 0.0)
+            base = lt if lt != 0.0 else (q * (upf or 0.0))
+            if mode == "gross":
+                s += base
+            else:
+                # net -> gross
+                s += base * (1.0 + (vr / 100.0)) if vr > 0 else base
+        return float(s)
+
+    chosen = "gross"
+    if total_with_vat is not None and total_with_vat != 0.0:
+        sum_g = _sum_for_mode("gross")
+        sum_n = _sum_for_mode("net")
+        diff_g = abs(sum_g - total_with_vat)
+        diff_n = abs(sum_n - total_with_vat)
+        chosen = "net" if diff_n + 1e-9 < diff_g else "gross"
+
+    # Kanonizace do (unit_net, line_gross)
+    for it in items:
+        name = str(it.get("name") or "").strip()
+        q = _f(it.get("quantity"), 1.0)
+        vr = _f(it.get("vat_rate"), 0.0)
+        lt = _f(it.get("line_total"), 0.0)
+        up = it.get("unit_price")
+        upf = None if up is None else _f(up, 0.0)
+        if q == 0.0:
+            q = 1.0
+            it["quantity"] = 1.0
+            reasons.append("oprava položky: quantity=0 nahrazeno 1")
+
+        # zaokrouhlení a podobné položky bereme jako gross==net
+        if "zaokrouhl" in name.lower():
+            it["vat_rate"] = 0.0
+            it["unit_price"] = round(lt if lt != 0.0 else (upf or 0.0), 2)
+            it["line_total"] = round(lt if lt != 0.0 else (upf or 0.0), 2)
+            continue
+
+        base = lt if lt != 0.0 else (q * (upf or 0.0))
+        if chosen == "net":
+            line_gross = base * (1.0 + (vr / 100.0)) if vr > 0 else base
+            unit_net = (base / q) if q else 0.0
+        else:
+            line_gross = base
+            unit_net = (base / q) / (1.0 + (vr / 100.0)) if (q and vr > 0) else ((base / q) if q else 0.0)
+
+        # finální zápis
+        it["unit_price"] = round(unit_net, 4)  # 4 desetinná místa zlepší následné přepočty
+        it["line_total"] = round(line_gross, 2)
+
+    # Ověření: podle unit_net * (1+vat) * qty musí sedět line_total a total
+    sum_calc = 0.0
+    for it in items:
+        q = _f(it.get("quantity"), 1.0)
+        vr = _f(it.get("vat_rate"), 0.0)
+        upn = _f(it.get("unit_price"), 0.0)
+        calc = (upn * (1.0 + vr / 100.0) * q) if vr > 0 else (upn * q)
+        calc = round(calc, 2)
+        lt = _f(it.get("line_total"), 0.0)
+        # pokud se liší o víc než haléř, přepiš na konzistentní výsledek
+        if abs(calc - lt) > 0.02:
+            it["line_total"] = calc
+            reasons.append("oprava položky: line_total přepočteno z unit_price_net*DPH*qty")
+        sum_calc += _f(it.get("line_total"), 0.0)
+
+    if total_with_vat is None or total_with_vat == 0.0:
+        return False
+    diff = abs(sum_calc - total_with_vat)
+    rel = diff / max(abs(total_with_vat), 1e-9)
+    return (diff <= abs_tol) or (rel <= rel_tol)
+
+
+def _norm_amount(s: str) -> float:
+    s = s.replace("\xa0", " ")
+    s = s.strip()
+    s = s.replace(" ", "")
+    s = s.replace(",", ".")
+    return float(s)
+
+def _f(v, default: float = 0.0) -> float:
+    if v is None:
+        return float(default)
+    if isinstance(v, (int, float)):
+        return float(v)
+    try:
+        s = str(v).strip().replace("\xa0", " ").replace(" ", "").replace(",", ".")
+        if not s:
+            return float(default)
+        return float(s)
+    except Exception:
+        return float(default)
+
+def _normalize_items(items: List[dict], reasons: List[str]) -> None:
+    """
+    Sjednotí položky do deterministické podoby pro výpočty:
+    - když chybí line_total a máme qty+unit_price -> dopočítá
+    - když line_total zjevně obsahuje jednotkovou cenu (qty>1 a line_total≈unit_price) -> opraví na qty*unit_price
+    """
+    for it in items:
+        q = _f(it.get("quantity"), 1.0)
+        up = it.get("unit_price")
+        upf = None if up is None else _f(up, 0.0)
+        lt = _f(it.get("line_total"), 0.0)
+        # dopočet, když line_total chybí
+        if (lt <= 0.0) and (upf is not None) and (q > 0):
+            it["line_total"] = round(q * upf, 2)
+            continue
+        # častý OCR/format case: line_total je ve skutečnosti jednotková cena
+        if (upf is not None) and (q > 1.0) and (lt > 0.0):
+            if abs(lt - upf) <= 0.02 and abs((q * upf) - lt) > 0.05:
+                it["line_total"] = round(q * upf, 2)
+                reasons.append("oprava položky: řádková cena dopočtena z qty*unit_price")
+
+
+def _safe_float(s: str) -> float:
+    return float(str(s).strip().replace("\xa0", " ").replace(" ", "").replace(",", "."))
+
+
+def _find_first(patterns: list[re.Pattern], text: str) -> Optional[str]:
+    for p in patterns:
+        m = p.search(text)
+        if m:
+            return m.group(1).strip()
+    return None
+
+
+def _normalize_ico_soft(ico: str | None) -> str | None:
+    if ico is None:
+        return None
+    raw = str(ico).strip()
+    if not raw:
+        return None
+    digits = _ICO_DIGITS_RE.sub("", raw)
+    if not digits:
+        return None
+    if len(digits) > 8:
+        # když OCR slije více čísel – raději vrátit původní digit-only; verifikace ARES stejně rozhodne
+        return digits
+    return digits.zfill(8)
+
+
+def _parse_date(s: str) -> Optional[dt.date]:
+    s = s.strip()
+    try:
+        # support dd.mm.yyyy and dd/mm/yyyy and ISO
+        d = dtparser.parse(s, dayfirst=True).date()
+        return d
+    except Exception:
+        return None
+
+
+def extract_from_text(text: str) -> Extracted:
+    raw = text or ""
+    t = raw
+
+    # IČO: dříve se bralo libovolné 8-číslí => často sebralo VS/číslo dokladu.
+    # Teď vyžadujeme kontext (IČO/ICO/IČ) a normalizujeme.
+    ico = _find_first(
+        [
+            re.compile(r"\bIČO\s*[: ]\s*([0-9][0-9\s-]{6,}[0-9])\b", re.IGNORECASE),
+            re.compile(r"\bICO\s*[: ]\s*([0-9][0-9\s-]{6,}[0-9])\b", re.IGNORECASE),
+            re.compile(r"\bIČ\s*[: ]\s*([0-9][0-9\s-]{6,}[0-9])\b", re.IGNORECASE),
+        ],
+        t,
+    )
+    ico = _normalize_ico_soft(ico)
+
+    doc_no = _find_first([
+        re.compile(r"Č[ií]slo\s+faktury\s*[: ]\s*([\w-]+)", re.IGNORECASE),
+        re.compile(r"Faktura\s*#\s*(\d+)", re.IGNORECASE),
+        re.compile(r"Č[ií]slo\s+objednávky\s*[: ]\s*([\w-]+)", re.IGNORECASE),
+        # Daňové doklady často mají číslo hned pod nadpisem bez "č."
+        re.compile(r"DAŇOVÝ\s+DOKLAD\s*(?:č\.?\s*)?\n?\s*([A-Z0-9][A-Z0-9-]{2,})\b", re.IGNORECASE),
+        re.compile(r"Faktura\s*-?\s*daňový\s+doklad\s+č\.?\s*([\w-]+)", re.IGNORECASE),
+        # Účtenky
+        re.compile(r"Ú?čtenka\s+č[ií]slo\s*[: ]\s*(\d{3,})\b", re.IGNORECASE),
+        re.compile(r"Doklad\s+č[ií]slo\s*[: ]\s*(\d{3,})\b", re.IGNORECASE),
+        # Variabilní symbol (u faktur často funguje jako stabilní identifikátor)
+        re.compile(r"\bVS\s*[: ]\s*(\d{3,})\b", re.IGNORECASE),
+    ], t)
+
+    bank_account = _find_first([
+        re.compile(r"\bIBAN\s*[: ]\s*([A-Z]{2}\d{2}[A-Z0-9]{10,})\b"),
+        re.compile(r"\bÚčet\s*[: ]\s*(\d{6,}-?\d{2,}/\d{4})\b", re.IGNORECASE),
+        re.compile(r"\b(\d{6,}-?\d{2,})\s*/\s*(\d{4})\b"),
+    ], t)
+    if bank_account and " " in bank_account:
+        bank_account = bank_account.replace(" ", "")
+
+    date_s = _find_first([
+        re.compile(r"Datum\s+vystaven[ií]\s*[: ]\s*([0-9]{1,2}[./][0-9]{1,2}[./][0-9]{2,4})", re.IGNORECASE),
+        re.compile(r"Datum\s*[: ]\s*([0-9]{1,2}[./][0-9]{1,2}[./][0-9]{2,4})", re.IGNORECASE),
+        # Účtenky často mají datum bez labelu, někdy i s časem (čas ignorujeme)
+        re.compile(r"\b([0-9]{1,2}\.[0-9]{1,2}\.[0-9]{2,4})\b"),
+        re.compile(r"\b([0-9]{2}/[0-9]{2}/[0-9]{4})\b"),
+    ], t)
+    issue_date = _parse_date(date_s) if date_s else None
+
+    # currency
+    currency = "CZK" if re.search(r"\bCZK\b|Kč", t) else "EUR" if re.search(r"\bEUR\b", t) else "CZK"
+
+    # total
+    total_s = _find_first([
+        re.compile(r"CELKEM\s+K\s+ÚHRADĚ\s*\n?\s*([0-9\s]+[.,][0-9]{2})", re.IGNORECASE),
+        re.compile(r"Celkem\s+k\s+úhradě\s*[: ]\s*([0-9\s]+[.,][0-9]{2})", re.IGNORECASE),
+        re.compile(r"K\s+zaplacení\s+celkem\s+EUR\s*([0-9\s]+[.,][0-9]{2})", re.IGNORECASE),
+        re.compile(r"Cena\s+celkem\s*([0-9\s]+[.,][0-9]{2})", re.IGNORECASE),
+        re.compile(r"Koruna\s+česká\s+Kč\s*([0-9\s]+[.,][0-9]{2})", re.IGNORECASE),
+        # Účtenky: "Celkem 68,20" / "PRODEJ 68,20 Kč"
+        re.compile(r"\bCelkem\s*[: ]\s*([0-9\s]+[.,][0-9]{2})\b", re.IGNORECASE),
+        re.compile(r"Celkem\s+v\s+\w+.*?([0-9\s]+[.,][0-9]{2})", re.IGNORECASE),
+        re.compile(r"\bPRODEJ\s*([0-9\s]+[.,][0-9]{2})\b", re.IGNORECASE),
+    ], t)
+
+    total = None
+    if total_s:
+        try:
+            total = _norm_amount(total_s)
+        except Exception:
+            total = None
+
+    items: List[dict] = []
+    # attempt parse tabular items (e.g., Rohlik PDF text)
+    # pattern: <name> <qty> ks <unit> Kč <vat%> % <...> <line_total> Kč
+    line_pat = re.compile(
+        r"^(?P<name>.+?)\s+(?P<qty>-?\d+(?:[.,]\d+)?)\s*(?:ks|x)?\s+(?P<unit>\d+[\s\d]*[.,]\d{2})\s*Kč\s+(?P<vat>\d{1,2})\s*%\s+.*?\s+(?P<total>-?\d+[\s\d]*[.,]\d{2})\s*Kč\s*$",
+        re.IGNORECASE
+    )
+
+    for ln in t.splitlines():
+        ln = ln.strip()
+        if not ln or len(ln) < 6:
+            continue
+        m = line_pat.match(ln)
+        if m:
+            try:
+                name = m.group("name").strip()
+                qty = _safe_float(m.group("qty"))
+                unit_price = _norm_amount(m.group("unit"))
+                vat = float(m.group("vat"))
+                line_total = _norm_amount(m.group("total"))
+                items.append({"name": name, "quantity": qty, "unit_price": unit_price, "vat_rate": vat, "line_total": line_total})
+            except Exception:
+                continue
+
+    
+    # Wolt faktury: řádky typu "<název> 12% 2 214,90 429,80" (bez "Kč" u čísel)
+    if not items:
+        wolt_pat = re.compile(
+            r"^(?P<name>.+?)\s+(?P<vat>\d{1,2})%\s+(?P<qty>\d+(?:[.,]\d+)?)\s+(?P<unit>\d+[\s\d]*[.,]\d{2})\s+(?P<total>-?\d+[\s\d]*[.,]\d{2})\s*$"
+        )
+        for ln in t.splitlines():
+            ln = ln.strip()
+            if not ln or len(ln) < 6:
+                continue
+            m = wolt_pat.match(ln)
+            if not m:
+                continue
+            try:
+                name = m.group("name").strip()
+                qty = _safe_float(m.group("qty"))
+                unit_price = _norm_amount(m.group("unit"))
+                vat = float(m.group("vat"))
+                line_total = _norm_amount(m.group("total"))
+                items.append({"name": name, "quantity": qty, "unit_price": unit_price, "vat_rate": vat, "line_total": line_total})
+            except Exception:
+                continue
+
+    # Better-hotel / Mevris: popis položky je často na 1-2 řádcích a ceny jsou ve formátu "... 294.14 CZK 1 294.14 CZK 355.91 CZK"
+    if not items:
+        # default VAT: vezmeme první explicitní sazbu (např. "21%") z dokumentu
+        vat_default = 0.0
+        mvat = re.search(r"\b(\d{1,2})%\b", t)
+        if mvat:
+            try:
+                vat_default = float(mvat.group(1))
+            except Exception:
+                vat_default = 0.0
+        bh_pat = re.compile(
+            r"(?P<net>\d+[\s\d]*[.,]\d{2})\s*CZK\s+(?P<qty>\d+(?:[.,]\d+)?)\s+(?P<net_total>\d+[\s\d]*[.,]\d{2})\s*CZK\s+(?P<gross>\d+[\s\d]*[.,]\d{2})\s*CZK",
+            re.IGNORECASE,
+        )
+        pending_desc: List[str] = []
+        for ln in t.splitlines():
+            ln = ln.strip()
+            if not ln:
+                continue
+            m = bh_pat.search(ln)
+            if not m:
+                # bereme jen "popis" řádky, ignorujeme hlavičky
+                if not re.search(r"^(POLOŽKA|CENA|POČET|CELKEM|DPH|DODAVATEL|ODBĚRATEL)\b", ln, re.IGNORECASE):
+                    pending_desc.append(ln)
+                continue
+            try:
+                name = " ".join(pending_desc).strip() or "Položka"
+                pending_desc = []
+                qty = _safe_float(m.group("qty"))
+                unit_net = _norm_amount(m.group("net"))
+                gross = _norm_amount(m.group("gross"))
+                items.append({"name": name, "quantity": qty, "unit_price": unit_net, "vat_rate": float(vat_default or 0.0), "line_total": gross})
+            except Exception:
+                pending_desc = []
+                continue
+# receipts (Albert): lines like "2 x 5,60 Kč 11,20"
+    if not items:
+        rec_pat = re.compile(r"^(?P<name>[A-ZÁČĎÉĚÍŇÓŘŠŤÚŮÝŽ0-9 .,'/-]{3,})\s*$")
+        qty_price_pat = re.compile(
+            r"^(?P<qty>\d+(?:[.,]\d+)?)\s*[xX]\s*(?P<unit>\d+[\s\d]*[.,]\d{2}).*?(?P<total>\d+[\s\d]*[.,]\d{2})\s*(?P<vat_letter>[A-Z])?\s*$"
+        )
+        pending_name: Optional[str] = None
+        for ln in t.splitlines():
+            ln = ln.strip()
+            if not ln:
+                continue
+            if pending_name is None:
+                if rec_pat.match(ln) and not re.search(r"(Celkem|DPH|Datum|Děkujeme|Kč|EUR|IBAN)", ln, re.IGNORECASE):
+                    pending_name = ln
+                continue
+            m2 = qty_price_pat.match(ln)
+            if m2:
+                try:
+                    qty = _safe_float(m2.group("qty"))
+                    unit_price = _norm_amount(m2.group("unit"))
+                    line_total = _norm_amount(m2.group("total"))
+                    vat_letter = (m2.group("vat_letter") or "").strip().upper()
+                    vat = _VAT_LETTER_MAP.get(vat_letter, 0.0)
+                    items.append({"name": pending_name, "quantity": qty, "unit_price": unit_price, "vat_rate": vat, "line_total": line_total})
+                except Exception:
+                    pass
+                pending_name = None
+            else:
+                pending_name = None
+
+    # zaokrouhlení (pokud existuje) přidáme jako samostatnou položku
+    items.extend(_extract_rounding_items(t))
+
+    # --- kontrola součtu položek vs. celkem ---
+    # Cíl: co nejvíc dokladů vyřešit offline, a na OpenAI posílat jen minimum.
+    reasons: List[str] = []
+    sum_ok = False
+    try:
+        sum_ok = _canonicalize_items_to_unit_net_and_line_gross(items, total, reasons)
+        if items and (total is not None) and not sum_ok:
+            reasons.append("nesedí součet položek vs. celkem")
+    except Exception:
+        if items and total is not None:
+            reasons.append("nelze ověřit součet položek")
+
+    # confidence heuristic
+    conf = 0.0
+    if ico:
+        conf += 0.25
+    else:
+        reasons.append("chybí IČO")
+    if doc_no:
+        conf += 0.15
+    else:
+        reasons.append("chybí číslo dokladu")
+    if issue_date:
+        conf += 0.15
+    else:
+        reasons.append("chybí datum")
+    if total is not None:
+        conf += 0.25
+    else:
+        reasons.append("chybí celková cena")
+    if items:
+        conf += 0.20
+    else:
+        reasons.append("chybí položky")
+
+    # Pokud máme explicitní problém se součtem, je to vždy NEROZPOZNANÉ (neprojde do OUT).
+    # „nízká jistota vytěžení“ ale přidáváme jen při nízké confidence, ne při součtových problémech.
+    requires_review = False
+    if conf < 0.75:
+        requires_review = True
+        reasons.append("nízká jistota vytěžení")
+    if items and (total is not None) and (not sum_ok):
+        requires_review = True
+
+    return Extracted(
+        supplier_ico=ico,
+        doc_number=doc_no,
+        bank_account=bank_account,
+        issue_date=issue_date,
+        total_with_vat=total,
+        currency=currency,
+        items=items,
+        confidence=min(conf, 1.0),
+        requires_review=requires_review,
+        review_reasons=reasons,
+        full_text=raw,
+    )
+
+
+def postprocess_items_for_db(
+    *,
+    items: List[dict],
+    total_with_vat: Optional[float],
+    reasons: Optional[List[str]] = None,
+) -> Tuple[bool, List[str]]:
+    """
+    Normalizuje položky do kanonického formátu používaného v DB a provede kontrolu součtu.
+
+    Použití:
+      - po offline extrakci je voláno implicitně v extract_from_text()
+      - po OpenAI fallbacku je potřeba volat znovu, protože OpenAI vrací položky v různém základu
+
+    Vrací (sum_ok, reasons).
+    """
+    rr: List[str] = list(reasons or [])
+    ok = False
+    try:
+        ok = _canonicalize_items_to_unit_net_and_line_gross(items, total_with_vat, rr)
+        if items and (total_with_vat is not None) and not ok:
+            rr.append("nesedí součet položek vs. celkem")
+    except Exception:
+        if items and (total_with_vat is not None):
+            rr.append("nelze ověřit součet položek")
+    # de-dup reasons (stabilní pořadí)
+    rr = list(dict.fromkeys(rr))
+    return ok, rr
diff --git a/src/kajovospend/integrations/__pycache__/__init__.cpython-311.pyc b/src/kajovospend/integrations/__pycache__/__init__.cpython-311.pyc
new file mode 100644
index 0000000..ef399b6
Binary files /dev/null and b/src/kajovospend/integrations/__pycache__/__init__.cpython-311.pyc differ
diff --git a/src/kajovospend/integrations/__pycache__/ares.cpython-311.pyc b/src/kajovospend/integrations/__pycache__/ares.cpython-311.pyc
new file mode 100644
index 0000000..6f053fb
Binary files /dev/null and b/src/kajovospend/integrations/__pycache__/ares.cpython-311.pyc differ
diff --git a/src/kajovospend/integrations/__pycache__/openai_fallback.cpython-311.pyc b/src/kajovospend/integrations/__pycache__/openai_fallback.cpython-311.pyc
new file mode 100644
index 0000000..1626d54
Binary files /dev/null and b/src/kajovospend/integrations/__pycache__/openai_fallback.cpython-311.pyc differ
diff --git a/src/kajovospend/ocr/__pycache__/__init__.cpython-311.pyc b/src/kajovospend/ocr/__pycache__/__init__.cpython-311.pyc
new file mode 100644
index 0000000..4d396fa
Binary files /dev/null and b/src/kajovospend/ocr/__pycache__/__init__.cpython-311.pyc differ
diff --git a/src/kajovospend/ocr/__pycache__/pdf_render.cpython-311.pyc b/src/kajovospend/ocr/__pycache__/pdf_render.cpython-311.pyc
new file mode 100644
index 0000000..1d91e81
Binary files /dev/null and b/src/kajovospend/ocr/__pycache__/pdf_render.cpython-311.pyc differ
diff --git a/src/kajovospend/ocr/__pycache__/rapidocr_engine.cpython-311.pyc b/src/kajovospend/ocr/__pycache__/rapidocr_engine.cpython-311.pyc
new file mode 100644
index 0000000..212d2d1
Binary files /dev/null and b/src/kajovospend/ocr/__pycache__/rapidocr_engine.cpython-311.pyc differ
diff --git a/src/kajovospend/ocr/rapidocr_engine.py b/src/kajovospend/ocr/rapidocr_engine.py
index ca2df76..d2591c3 100644
--- a/src/kajovospend/ocr/rapidocr_engine.py
+++ b/src/kajovospend/ocr/rapidocr_engine.py
@@ -1,24 +1,17 @@
 from __future__ import annotations
-
 from dataclasses import dataclass
 from pathlib import Path
 from typing import List, Tuple
-
 import numpy as np
-from PIL import Image
-
+from PIL import Image, ImageOps, ImageFilter
 try:
     from rapidocr_onnxruntime import RapidOCR
 except Exception:  # pragma: no cover
     RapidOCR = None  # type: ignore
-
-
 @dataclass
 class OcrLine:
     text: str
     confidence: float
-
-
 class RapidOcrEngine:
     def __init__(self, models_dir: Path | None = None):
         # Do NOT hard-fail the whole app if OCR runtime isn't available.
@@ -40,10 +33,85 @@ class RapidOcrEngine:
             kwargs["rec_char_dict_path"] = str(keys) if keys.exists() else None
             kwargs = {k: v for k, v in kwargs.items() if v}
         self._engine = RapidOCR(**kwargs)
-
     def is_available(self) -> bool:
         return self._engine is not None
-
+    def _preprocess_variants(self, image: Image.Image) -> List[Image.Image]:
+        """Vytvoří několik variant obrázku pro robustnější OCR (slabý kontrast, malý doklad uprostřed stránky)."""
+        variants: List[Image.Image] = []
+        try:
+            base = image.convert("RGB")
+            variants.append(base)
+            # 1) Autocrop "obsahu" (odstraní velké bílé okraje u skenů)
+            g = ImageOps.grayscale(base)
+            g2 = ImageOps.autocontrast(g)
+            arr = np.array(g2)
+            # mask: všechno, co není téměř bílé
+            thr = int(np.percentile(arr, 98))
+            mask = arr < max(200, thr - 5)
+            if mask.any():
+                ys, xs = np.where(mask)
+                y0, y1 = int(ys.min()), int(ys.max())
+                x0, x1 = int(xs.min()), int(xs.max())
+                pad = int(0.03 * max(arr.shape[0], arr.shape[1])) + 10
+                y0 = max(0, y0 - pad)
+                x0 = max(0, x0 - pad)
+                y1 = min(arr.shape[0] - 1, y1 + pad)
+                x1 = min(arr.shape[1] - 1, x1 + pad)
+                cropped = base.crop((x0, y0, x1 + 1, y1 + 1))
+            else:
+                cropped = base
+            variants.append(cropped)
+            # 2) Kontrast + doostření + upscaling
+            for src in [cropped]:
+                gg = ImageOps.grayscale(src)
+                gg = ImageOps.autocontrast(gg)
+                # upscale (malé účtenky)
+                scale = 2
+                if max(gg.size) < 1400:
+                    scale = 3
+                up = gg.resize((gg.size[0] * scale, gg.size[1] * scale), Image.Resampling.LANCZOS)
+                up = up.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3))
+                # 3) Otsu binarizace (pomáhá u vybledlých skenů)
+                a = np.array(up)
+                # histogram 256
+                hist = np.bincount(a.flatten(), minlength=256).astype(np.float64)
+                total = a.size
+                sum_total = np.dot(np.arange(256), hist)
+                sum_b, w_b, w_f, var_max, thr_otsu = 0.0, 0.0, 0.0, 0.0, 0
+                for i in range(256):
+                    w_b += hist[i]
+                    if w_b == 0:
+                        continue
+                    w_f = total - w_b
+                    if w_f == 0:
+                        break
+                    sum_b += i * hist[i]
+                    m_b = sum_b / w_b
+                    m_f = (sum_total - sum_b) / w_f
+                    var_between = w_b * w_f * (m_b - m_f) ** 2
+                    if var_between > var_max:
+                        var_max = var_between
+                        thr_otsu = i
+                bw = (a > thr_otsu).astype(np.uint8) * 255
+                bw_img = Image.fromarray(bw, mode="L")
+                variants.append(bw_img.convert("RGB"))
+        except Exception:
+            # fallback: at least base
+            return [image.convert("RGB")]
+        # dedupe by size/mode quickly
+        out: List[Image.Image] = []
+        seen = set()
+        for v in variants:
+            key = (v.size, v.mode)
+            if key in seen:
+                continue
+            seen.add(key)
+            out.append(v)
+        return out
+    def _score_text(self, text: str, conf: float) -> float:
+        # prefer higher confidence and more content (but not too aggressively)
+        ln = len((text or "").strip())
+        return float(conf or 0.0) * (1.0 + min(2.0, np.log1p(max(0, ln)) / 3.0))
     def image_to_lines(self, image: Image.Image) -> List[OcrLine]:
         if self._engine is None:
             return []
@@ -62,10 +130,23 @@ class RapidOcrEngine:
             if text:
                 lines.append(OcrLine(text=text, confidence=score))
         return lines
-
     def image_to_text(self, image: Image.Image) -> Tuple[str, float]:
-        lines = self.image_to_lines(image)
-        if not lines:
+        if self._engine is None:
+            return "", 0.0
+        best_text = ""
+        best_conf = 0.0
+        best_score = -1.0
+        for variant in self._preprocess_variants(image):
+            lines = self.image_to_lines(variant)
+            if not lines:
+                continue
+            avg = sum(l.confidence for l in lines) / len(lines)
+            text = "\n".join(l.text for l in lines)
+            score = self._score_text(text, float(avg))
+            if score > best_score:
+                best_score = score
+                best_text = text
+                best_conf = float(avg)
+        if not best_text:
             return "", 0.0
-        avg = sum(l.confidence for l in lines) / len(lines)
-        return "\n".join(l.text for l in lines), float(avg)
+        return best_text, float(best_conf)
\ No newline at end of file
diff --git a/src/kajovospend/service/__pycache__/__init__.cpython-311.pyc b/src/kajovospend/service/__pycache__/__init__.cpython-311.pyc
new file mode 100644
index 0000000..9aa9949
Binary files /dev/null and b/src/kajovospend/service/__pycache__/__init__.cpython-311.pyc differ
diff --git a/src/kajovospend/service/__pycache__/app.cpython-311.pyc b/src/kajovospend/service/__pycache__/app.cpython-311.pyc
new file mode 100644
index 0000000..85cdc0b
Binary files /dev/null and b/src/kajovospend/service/__pycache__/app.cpython-311.pyc differ
diff --git a/src/kajovospend/service/__pycache__/control.cpython-311.pyc b/src/kajovospend/service/__pycache__/control.cpython-311.pyc
new file mode 100644
index 0000000..0306074
Binary files /dev/null and b/src/kajovospend/service/__pycache__/control.cpython-311.pyc differ
diff --git a/src/kajovospend/service/__pycache__/control_client.cpython-311.pyc b/src/kajovospend/service/__pycache__/control_client.cpython-311.pyc
new file mode 100644
index 0000000..b711990
Binary files /dev/null and b/src/kajovospend/service/__pycache__/control_client.cpython-311.pyc differ
diff --git a/src/kajovospend/service/__pycache__/processor.cpython-311.pyc b/src/kajovospend/service/__pycache__/processor.cpython-311.pyc
new file mode 100644
index 0000000..61f9412
Binary files /dev/null and b/src/kajovospend/service/__pycache__/processor.cpython-311.pyc differ
diff --git a/src/kajovospend/service/__pycache__/watcher.cpython-311.pyc b/src/kajovospend/service/__pycache__/watcher.cpython-311.pyc
new file mode 100644
index 0000000..ad0980f
Binary files /dev/null and b/src/kajovospend/service/__pycache__/watcher.cpython-311.pyc differ
diff --git a/src/kajovospend/service/processor.py b/src/kajovospend/service/processor.py
index a9e9246..b3e7d0e 100644
--- a/src/kajovospend/service/processor.py
+++ b/src/kajovospend/service/processor.py
@@ -1,481 +1,484 @@
-from __future__ import annotations
-
-import datetime as dt
-import shutil
-import io
-import re
-from pathlib import Path
-from typing import Any, Dict, Optional, Tuple, List
-
-from PIL import Image
-from pypdf import PdfReader
-from sqlalchemy import text
-
-from kajovospend.db.models import ImportJob
-from kajovospend.db.queries import (
-    add_document,
-    create_file_record,
-    rebuild_fts_for_document,
-    upsert_supplier,
-)
-from kajovospend.extract.parser import extract_from_text, postprocess_items_for_db
-from kajovospend.integrations.ares import fetch_by_ico, normalize_ico
-from kajovospend.integrations.openai_fallback import OpenAIConfig, extract_with_openai
-from kajovospend.ocr.pdf_render import render_pdf_to_images
-from kajovospend.ocr.rapidocr_engine import RapidOcrEngine
-from kajovospend.utils.hashing import sha256_file
-
-
-def safe_move(src: Path, dst_dir: Path, target_name: str) -> Path:
-    dst_dir.mkdir(parents=True, exist_ok=True)
-    dst = dst_dir / target_name
-    if dst.exists():
-        stem = dst.stem
-        suffix = dst.suffix
-        i = 1
-        while True:
-            cand = dst_dir / f"{stem}_{i}{suffix}"
-            if not cand.exists():
-                dst = cand
-                break
-            i += 1
-    shutil.move(str(src), str(dst))
-    return dst
-
-
-class Processor:
-    def __init__(self, cfg: Dict[str, Any], paths, logger):
-        self.cfg = cfg
-        self.paths = paths
-        self.log = logger
-        # OCR engine is optional; if unavailable we quarantine rather than crash service.
-        try:
-            self.ocr_engine = RapidOcrEngine(paths.models_dir)
-        except Exception as e:
-            self.log.warning(f"OCR init failed; will quarantine documents. Error: {e}")
-            self.ocr_engine = None
-
-    def _openai_images_for_path(self, path: Path) -> List[Tuple[str, bytes]]:
-        """
-        Připraví obrazové vstupy pro OpenAI fallback.
-        - PDF: render první 1-2 strany do PNG (rozumný kompromis cena/výkon).
-        - image: vezme bytes přímo (png/jpg/webp).
-        """
-        images: List[Tuple[str, bytes]] = []
-        try:
-            suf = path.suffix.lower()
-            if suf == ".pdf":
-                dpi = int(self.cfg["ocr"].get("pdf_dpi", 200))
-                pages = render_pdf_to_images(path, dpi=dpi)
-                for img in pages[:2]:
-                    buf = io.BytesIO()
-                    # PNG je robustní pro text/čáry; optimalize kvůli velikosti
-                    img.save(buf, format="PNG", optimize=True)
-                    images.append(("image/png", buf.getvalue()))
-            else:
-                mime = "image/png"
-                if suf in (".jpg", ".jpeg"):
-                    mime = "image/jpeg"
-                elif suf == ".webp":
-                    mime = "image/webp"
-                data = path.read_bytes()
-                if data:
-                    images.append((mime, data))
-        except Exception as e:
-            self.log.debug(f"OpenAI image prep failed ({path.name}): {e}")
-        return images
-
-    def _ocr_pdf_pages(self, pdf_path: Path) -> Tuple[List[str], List[float], int]:
-        """
-        Vrátí OCR text po jednotlivých stránkách:
-        - embedded text: per page extract_text()
-        - jinak: render->OCR per page
-        """
-        # Try embedded text first (page-by-page)
-        try:
-            reader = PdfReader(str(pdf_path))
-            texts: List[str] = []
-            for page in reader.pages:
-                t = page.extract_text() or ""
-                texts.append(t)
-            # if at least one page has real text, treat as embedded text mode
-            if any((t or "").strip() for t in texts):
-                confs = [0.95 if (t or "").strip() else 0.0 for t in texts]
-                return texts, confs, len(texts)
-        except Exception:
-            pass
-
-        # fallback to image OCR
-        if self.ocr_engine is None:
-            return [], [], 0
-        images = render_pdf_to_images(pdf_path, dpi=int(self.cfg["ocr"].get("pdf_dpi", 200)))
-        texts2: List[str] = []
-        confs2: List[float] = []
-        for img in images:
-            t, c = self.ocr_engine.image_to_text(img)
-            texts2.append(t or "")
-            confs2.append(float(c or 0.0))
-        return texts2, confs2, len(images)
-
-    def _merge_extracted_by_key(self, per_page: List[Tuple[int, Any, str, float]]) -> List[Dict[str, Any]]:
-        """
-        per_page: [(page_no, Extracted, full_text, ocr_conf), ...]
-        Sloučí sousední stránky do 1 dokladu, pokud sedí klíč:
-          (supplier_ico, doc_number, issue_date)
-        Když klíč není kompletní, neslučuje (bezpečnější deterministické chování).
-        """
-        merged: List[Dict[str, Any]] = []
-        cur: Dict[str, Any] | None = None
-        for page_no, ex, full_text, ocr_conf in per_page:
-            key = (ex.supplier_ico, ex.doc_number, ex.issue_date)
-            key_ok = bool(ex.supplier_ico and ex.doc_number and ex.issue_date)
-            if cur is None:
-                cur = {
-                    "page_from": page_no,
-                    "page_to": page_no,
-                    "extracted": ex,
-                    "full_text": full_text or "",
-                    "ocr_conf": float(ocr_conf or 0.0),
-                    "key": key if key_ok else None,
-                }
-                continue
-            # merge only if both have complete key and keys match and pages are consecutive
-            if key_ok and cur.get("key") is not None and cur["key"] == key and page_no == int(cur["page_to"]) + 1:
-                cur["page_to"] = page_no
-                # merge items + text
-                try:
-                    cur_ex = cur["extracted"]
-                    cur_ex.items = list(cur_ex.items or []) + list(ex.items or [])
-                    # keep "best" confidence; requires_review if any says review
-                    cur_ex.confidence = float(max(cur_ex.confidence or 0.0, ex.confidence or 0.0))
-                    cur_ex.requires_review = bool(cur_ex.requires_review or ex.requires_review)
-                    cur_ex.review_reasons = list(dict.fromkeys((cur_ex.review_reasons or []) + (ex.review_reasons or [])))
-                    # total_with_vat: keep first non-null (multi-page invoice often repeats totals only at end)
-                    if cur_ex.total_with_vat is None and ex.total_with_vat is not None:
-                        cur_ex.total_with_vat = ex.total_with_vat
-                    cur["extracted"] = cur_ex
-                except Exception:
-                    pass
-                cur["full_text"] = (cur["full_text"] + "\n\n" + (full_text or "")).strip()
-                cur["ocr_conf"] = float(sum([cur["ocr_conf"], float(ocr_conf or 0.0)]) / 2.0)
-            else:
-                merged.append(cur)
-                cur = {
-                    "page_from": page_no,
-                    "page_to": page_no,
-                    "extracted": ex,
-                    "full_text": full_text or "",
-                    "ocr_conf": float(ocr_conf or 0.0),
-                    "key": key if key_ok else None,
-                }
-        if cur is not None:
-            merged.append(cur)
-        return merged
-
-    def _ocr_image(self, path: Path) -> Tuple[str, float, int]:
-        if self.ocr_engine is None:
-            return "", 0.0, 1
-        with Image.open(path) as img:
-            t, c = self.ocr_engine.image_to_text(img)
-        return t, c, 1
-
-    def _guess_supplier_ico_from_text(self, text: str) -> Optional[str]:
-        """Best-effort: pokud OCR nevyčetl IČO pomocí kontextu, zkus najít 8místné kandidáty.
-
-        Strategie:
-        - vytáhne všechny 8-místné sekvence číslic
-        - zkusí je ověřit přes ARES (rychlý timeout)
-        - když vyjde právě 1, vrátí ji
-
-        Pozn.: cíleně nevrací víc kandidátů, abychom nevytvářeli falešně pozitivní dodavatele.
-        """
-        if not text:
-            return None
-        cands = []
-        for m in re.finditer(r"\b\d{8}\b", text):
-            cands.append(m.group(0))
-        # de-dup, stabilní pořadí
-        seen = set()
-        uniq = []
-        for c in cands:
-            if c not in seen:
-                uniq.append(c)
-                seen.add(c)
-
-        valid: List[str] = []
-        for c in uniq[:20]:
-            try:
-                ico_n = normalize_ico(c)
-            except Exception:
-                continue
-            try:
-                # rychlá validace přes ARES
-                fetch_by_ico(ico_n, timeout=4)
-                valid.append(ico_n)
-            except Exception:
-                continue
-            if len(valid) > 1:
-                break
-        if len(valid) == 1:
-            return valid[0]
-        return None
-
-    def process_path(self, session, path: Path) -> Dict[str, Any]:
-        # returns dict with outcome
-        sha = sha256_file(path)
-        # dedupe check
-        existing = session.execute(
-            text("SELECT id, status FROM files WHERE sha256 = :sha"),
-            {"sha": sha},
-        ).fetchone()
-        if existing:
-            # duplicate file, move to DUPLICITY
-            out_base = Path(self.cfg["paths"]["output_dir"])
-            dup_dir = out_base / self.cfg["paths"].get("duplicate_dir_name", "DUPLICITY")
-            moved = safe_move(path, dup_dir, path.name)
-            return {"status": "DUPLICATE", "sha256": sha, "moved_to": str(moved)}
-
-        # OCR
-        min_conf = float(self.cfg["ocr"].get("min_confidence", 0.65))
-        pages = 1
-        per_doc_chunks: List[Dict[str, Any]] = []
-
-        if path.suffix.lower() == ".pdf":
-            page_texts, page_confs, pages = self._ocr_pdf_pages(path)
-            if not page_texts:
-                # no text => hard quarantine later
-                page_texts = []
-                page_confs = []
-                pages = 0
-            per_page: List[Tuple[int, Any, str, float]] = []
-            for i, t in enumerate(page_texts, start=1):
-                ex = extract_from_text(t or "")
-                per_page.append((i, ex, t or "", float(page_confs[i - 1] if i - 1 < len(page_confs) else 0.0)))
-            # Merge multi-page invoices deterministically by key
-            per_doc_chunks = self._merge_extracted_by_key(per_page)
-        else:
-            ocr_text, ocr_conf, pages = self._ocr_image(path)
-            ex = extract_from_text(ocr_text or "")
-            per_doc_chunks = [{
-                "page_from": 1,
-                "page_to": 1,
-                "extracted": ex,
-                "full_text": ocr_text or "",
-                "ocr_conf": float(ocr_conf or 0.0),
-                "key": None,
-            }]
-
-        out_base = Path(self.cfg["paths"]["output_dir"])
-        quarantine_dir = out_base / self.cfg["paths"].get("quarantine_dir_name", "KARANTENA")
-
-        # create file record once (1 file can contain multiple documents)
-        file_record = create_file_record(
-            session,
-            sha256=sha,
-            original_name=path.name,
-            path=str(path),
-            pages=int(pages or 1),
-            status="NEW",
-            mime_type="application/pdf" if path.suffix.lower() == ".pdf" else "image",
-        )
-
-        created_doc_ids: List[int] = []
-        any_requires_review = False
-        any_processed = False
-        method_global = "offline"
-
-        # per-document processing within the file
-        for chunk in per_doc_chunks:
-            extracted = chunk["extracted"]
-            ocr_conf = float(chunk.get("ocr_conf") or 0.0)
-            ocr_text = chunk.get("full_text") or ""
-            page_from = int(chunk.get("page_from") or 1)
-            page_to = int(chunk.get("page_to") or page_from)
-
-            method = "offline"
-            reasons = list(extracted.review_reasons or [])
-
-            # Pokud chybí IČO, zkus heuristiku: najít 8-místné číslo a ověřit v ARES.
-            if not extracted.supplier_ico:
-                guessed_ico = self._guess_supplier_ico_from_text(ocr_text)
-                if guessed_ico:
-                    extracted.supplier_ico = guessed_ico
-                    extracted.confidence = float(max(extracted.confidence or 0.0, 0.80))
-                    reasons.append("IČO doplněno heuristikou (ARES validace)")
-
-            # OpenAI fallback: for PDF, it’s file-level images; OK as a first deterministic step
-            if (extracted.requires_review or extracted.confidence < 0.75) and self.cfg.get("openai", {}).get("enabled"):
-                api_key = str(self.cfg["openai"].get("api_key") or "").strip()
-                model = str(self.cfg["openai"].get("model") or "").strip()
-                if api_key and model:
-                    try:
-                        imgs = self._openai_images_for_path(path)
-                        obj, raw = extract_with_openai(
-                            OpenAIConfig(api_key=api_key, model=model),
-                            ocr_text,
-                            images=imgs if imgs else None,
-                        )
-                        if obj:
-                            extracted.supplier_ico = obj.get("supplier_ico") or extracted.supplier_ico
-                            extracted.doc_number = obj.get("doc_number") or extracted.doc_number
-                            extracted.bank_account = obj.get("bank_account") or extracted.bank_account
-                            if obj.get("issue_date"):
-                                try:
-                                    extracted.issue_date = dt.date.fromisoformat(obj["issue_date"])
-                                except Exception:
-                                    pass
-                            if obj.get("total_with_vat") is not None:
-                                try:
-                                    extracted.total_with_vat = float(obj["total_with_vat"])
-                                except Exception:
-                                    pass
-                            if obj.get("currency"):
-                                extracted.currency = str(obj.get("currency"))
-                            if obj.get("items"):
-                                extracted.items = list(obj.get("items"))
-                            extracted.confidence = float(max(extracted.confidence or 0.0, 0.85))
-                            method = "openai"
-                            method_global = "openai"
-                    except Exception as e:
-                        self.log.warning(f"OpenAI fallback failed: {e}")
-
-            # Po offline i OpenAI: kanonizace položek (unit_price bez DPH, line_total s DPH) + kontrola součtu.
-            items_ref = list(extracted.items or [])
-            sum_ok, reasons = postprocess_items_for_db(
-                items=items_ref,
-                total_with_vat=extracted.total_with_vat,
-                reasons=reasons,
-            )
-            extracted.items = items_ref
-            extracted.review_reasons = reasons
-
-            # Povinné minimum pro přesun do OUT:
-            # - IČO, číslo dokladu, datum, total (vč. DPH)
-            # - položky
-            # - součet položek (včetně zaokrouhlení) sedí na total v toleranci
-            complete = bool(
-                extracted.supplier_ico
-                and extracted.doc_number
-                and extracted.issue_date
-                and (extracted.total_with_vat is not None)
-                and (len(list(extracted.items or [])) > 0)
-                and sum_ok
-            )
-
-            requires_review = bool((not complete) or (ocr_conf < min_conf))
-            if ocr_conf < min_conf:
-                reasons.append("nízká jistota OCR")
-            if not complete:
-                reasons.append("nekompletní vytěžení")
-
-            # zapiš zpět pro UI/DB konzistenci
-            extracted.requires_review = requires_review
-            # de-dup důvodů, stabilní pořadí
-            extracted.review_reasons = list(dict.fromkeys(reasons))
-
-            supplier_id = None
-            if extracted.supplier_ico:
-                try:
-                    extracted.supplier_ico = normalize_ico(extracted.supplier_ico)
-                except Exception:
-                    pass
-                try:
-                    ares = fetch_by_ico(extracted.supplier_ico)
-                    s = upsert_supplier(
-                        session,
-                        ares.ico,
-                        name=ares.name,
-                        dic=ares.dic,
-                        address=ares.address,
-                        is_vat_payer=ares.is_vat_payer,
-                        ares_last_sync=ares.fetched_at,
-                        legal_form=ares.legal_form,
-                        street=ares.street,
-                        street_number=ares.street_number,
-                        orientation_number=ares.orientation_number,
-                        city=ares.city,
-                        zip_code=ares.zip_code,
-                        overwrite=True,
-                    )
-                    supplier_id = s.id
-                    extracted.supplier_ico = ares.ico
-                except Exception as e:
-                    reasons.append(f"ARES selhal: {e}")
-                    requires_review = True
-
-            # Business duplicita per-doc
-            if extracted.supplier_ico and extracted.doc_number and extracted.issue_date:
-                try:
-                    dup = session.execute(
-                        text(
-                            "SELECT id FROM documents "
-                            "WHERE supplier_ico = :ico AND doc_number = :dn AND issue_date = :d "
-                            "LIMIT 1"
-                        ),
-                        {"ico": extracted.supplier_ico, "dn": extracted.doc_number, "d": extracted.issue_date},
-                    ).fetchone()
-                    if dup:
-                        dup_dir = out_base / self.cfg["paths"].get("duplicate_dir_name", "DUPLICITY")
-                        moved = safe_move(path, dup_dir, path.name)
-                        file_record.current_path = str(moved)
-                        file_record.status = "DUPLICATE"
-                        file_record.processed_at = dt.datetime.utcnow()
-                        session.add(file_record)
-                        session.flush()
-                        return {
-                            "status": "DUPLICATE",
-                            "sha256": sha,
-                            "file_id": file_record.id,
-                            "moved_to": str(moved),
-                            "duplicate_of_document_id": int(dup[0]),
-                        }
-                except Exception as e:
-                    reasons.append(f"dup-check selhal: {e}")
-                    requires_review = True
-
-            doc = add_document(
-                session,
-                file_id=file_record.id,
-                supplier_id=supplier_id,
-                supplier_ico=extracted.supplier_ico,
-                doc_number=extracted.doc_number,
-                bank_account=extracted.bank_account,
-                issue_date=extracted.issue_date,
-                total_with_vat=extracted.total_with_vat,
-                currency=extracted.currency,
-                confidence=float(extracted.confidence),
-                method=method,
-                requires_review=requires_review,
-                review_reasons="; ".join(reasons) if reasons else None,
-                items=extracted.items,
-                page_from=page_from,
-                page_to=page_to,
-            )
-            rebuild_fts_for_document(session, doc.id, extracted.full_text if hasattr(extracted, "full_text") else ocr_text)
-            created_doc_ids.append(int(doc.id))
-            any_requires_review = bool(any_requires_review or requires_review)
-            any_processed = True
-
-        # Move file once (based on any_requires_review)
-        out_base = Path(self.cfg["paths"]["output_dir"])
-        quarantine_dir = out_base / self.cfg["paths"].get("quarantine_dir_name", "KARANTENA")
-        if any_requires_review or (not any_processed):
-            moved = safe_move(path, quarantine_dir, path.name)
-            status = "QUARANTINE"
-        else:
-            moved = safe_move(path, out_base, path.name)
-            status = "PROCESSED"
-
-        file_record.current_path = str(moved)
-        file_record.status = status
-        file_record.processed_at = dt.datetime.utcnow()
-        session.add(file_record)
-        session.flush()
-
-        return {
-            "status": status,
-            "sha256": sha,
-            "file_id": file_record.id,
-            "document_ids": created_doc_ids,
-            "moved_to": str(moved),
-        }
+from __future__ import annotations
+
+import datetime as dt
+import shutil
+import io
+import re
+from pathlib import Path
+from typing import Any, Dict, Optional, Tuple, List
+
+from PIL import Image
+from pypdf import PdfReader
+from sqlalchemy import text
+
+from kajovospend.db.models import ImportJob
+from kajovospend.db.queries import (
+    add_document,
+    create_file_record,
+    rebuild_fts_for_document,
+    upsert_supplier,
+)
+from kajovospend.extract.parser import extract_from_text, postprocess_items_for_db
+from kajovospend.integrations.ares import fetch_by_ico, normalize_ico
+from kajovospend.ocr.pdf_render import render_pdf_to_images
+from kajovospend.ocr.rapidocr_engine import RapidOcrEngine
+from kajovospend.utils.hashing import sha256_file
+
+
+def safe_move(src: Path, dst_dir: Path, target_name: str) -> Path:
+    dst_dir.mkdir(parents=True, exist_ok=True)
+    dst = dst_dir / target_name
+    if dst.exists():
+        stem = dst.stem
+        suffix = dst.suffix
+        i = 1
+        while True:
+            cand = dst_dir / f"{stem}_{i}{suffix}"
+            if not cand.exists():
+                dst = cand
+                break
+            i += 1
+    shutil.move(str(src), str(dst))
+    return dst
+
+
+class Processor:
+    def __init__(self, cfg: Dict[str, Any], paths, logger):
+        self.cfg = cfg
+        self.paths = paths
+        self.log = logger
+        # OCR engine is optional; if unavailable we quarantine rather than crash service.
+        try:
+            self.ocr_engine = RapidOcrEngine(paths.models_dir)
+        except Exception as e:
+            self.log.warning(f"OCR init failed; will quarantine documents. Error: {e}")
+            self.ocr_engine = None
+
+    def _ocr_pdf_pages(self, pdf_path: Path, status_cb=None) -> Tuple[List[str], List[float], int]:
+        """
+        Vrátí OCR text po jednotlivých stránkách:
+        - embedded text: per page extract_text()
+        - jinak: render->OCR per page
+        """
+        # Try embedded text first (page-by-page)
+        if status_cb:
+            status_cb("PDF: čtu text (bez OCR)…")
+        try:
+            reader = PdfReader(str(pdf_path))
+            texts: List[str] = []
+            for page in reader.pages:
+                t = page.extract_text() or ""
+                texts.append(t)
+            # if at least one page has real text, treat as embedded text mode
+            if any((t or "").strip() for t in texts):
+                confs = [0.95 if (t or "").strip() else 0.0 for t in texts]
+                return texts, confs, len(texts)
+        except Exception:
+            pass
+
+        # fallback to image OCR
+        if self.ocr_engine is None:
+            return [], [], 0
+        dpi_cfg = int(self.cfg["ocr"].get("pdf_dpi", 200))
+        dpi = max(300, dpi_cfg)
+        if status_cb:
+            status_cb(f"PDF: render na obrázky ({dpi} DPI)…")
+        images = render_pdf_to_images(pdf_path, dpi=dpi)
+        texts2: List[str] = []
+        confs2: List[float] = []
+        for idx_page, img in enumerate(images, start=1):
+            if status_cb:
+                status_cb(f"OCR: strana {idx_page}/{len(images)}…")
+            t, c = self.ocr_engine.image_to_text(img)
+            texts2.append(t or "")
+            confs2.append(float(c or 0.0))
+        return texts2, confs2, len(images)
+
+    def _merge_extracted_by_key(self, per_page: List[Tuple[int, Any, str, float]]) -> List[Dict[str, Any]]:
+        """
+        per_page: [(page_no, Extracted, full_text, ocr_conf), ...]
+        Sloučí sousední stránky do 1 dokladu, pokud sedí klíč:
+          (supplier_ico, doc_number, issue_date)
+        Když klíč není kompletní, neslučuje (bezpečnější deterministické chování).
+        """
+        merged: List[Dict[str, Any]] = []
+        cur: Dict[str, Any] | None = None
+        for page_no, ex, full_text, ocr_conf in per_page:
+            key = (ex.supplier_ico, ex.doc_number, ex.issue_date)
+            key_ok = bool(ex.supplier_ico and ex.doc_number and ex.issue_date)
+            if cur is None:
+                cur = {
+                    "page_from": page_no,
+                    "page_to": page_no,
+                    "extracted": ex,
+                    "full_text": full_text or "",
+                    "ocr_conf": float(ocr_conf or 0.0),
+                    "key": key if key_ok else None,
+                }
+                continue
+            # merge only if both have complete key and keys match and pages are consecutive
+            if key_ok and cur.get("key") is not None and cur["key"] == key and page_no == int(cur["page_to"]) + 1:
+                cur["page_to"] = page_no
+                # merge items + text
+                try:
+                    cur_ex = cur["extracted"]
+                    cur_ex.items = list(cur_ex.items or []) + list(ex.items or [])
+                    # keep "best" confidence; requires_review if any says review
+                    cur_ex.confidence = float(max(cur_ex.confidence or 0.0, ex.confidence or 0.0))
+                    cur_ex.requires_review = bool(cur_ex.requires_review or ex.requires_review)
+                    cur_ex.review_reasons = list(dict.fromkeys((cur_ex.review_reasons or []) + (ex.review_reasons or [])))
+                    # total_with_vat: keep first non-null (multi-page invoice often repeats totals only at end)
+                    if cur_ex.total_with_vat is None and ex.total_with_vat is not None:
+                        cur_ex.total_with_vat = ex.total_with_vat
+                    cur["extracted"] = cur_ex
+                except Exception:
+                    pass
+                cur["full_text"] = (cur["full_text"] + "\n\n" + (full_text or "")).strip()
+                cur["ocr_conf"] = float(sum([cur["ocr_conf"], float(ocr_conf or 0.0)]) / 2.0)
+            else:
+                merged.append(cur)
+                cur = {
+                    "page_from": page_no,
+                    "page_to": page_no,
+                    "extracted": ex,
+                    "full_text": full_text or "",
+                    "ocr_conf": float(ocr_conf or 0.0),
+                    "key": key if key_ok else None,
+                }
+        if cur is not None:
+            merged.append(cur)
+        return merged
+
+    def _ocr_image(self, path: Path, status_cb=None) -> Tuple[str, float, int]:
+        if self.ocr_engine is None:
+            return "", 0.0, 1
+        if status_cb:
+            status_cb("OCR: zpracovávám obrázek…")
+        with Image.open(path) as img:
+            t, c = self.ocr_engine.image_to_text(img)
+        return t, c, 1
+
+    def _guess_supplier_ico_from_text(self, text: str) -> Optional[str]:
+        """Best-effort: pokud OCR nevyčetl IČO pomocí kontextu, zkus najít 8místné kandidáty.
+
+        Strategie:
+        - vytáhne všechny 8-místné sekvence číslic
+        - zkusí je ověřit přes ARES (rychlý timeout)
+        - když vyjde právě 1, vrátí ji
+
+        Pozn.: cíleně nevrací víc kandidátů, abychom nevytvářeli falešně pozitivní dodavatele.
+        """
+        if not text:
+            return None
+
+    def _looks_like_ico(self, ico: str | None) -> bool:
+        if not ico:
+            return False
+        s = str(ico).strip()
+        return bool(re.fullmatch(r"\d{6,10}", s))
+
+    def _extract_supplier_name_guess(self, text: str) -> str | None:
+        """Heuristika pro účtenky bez IČO: vezme první 'rozumný' řádek v horní části."""
+        if not text:
+            return None
+        for ln in (text.splitlines()[:30]):
+            ln = str(ln).strip()
+            if not ln:
+                continue
+            # ignoruj generické a šum
+            if re.search(r"(daňov|doklad|účtenk|uctenk|datum|celkem|prodej|platba|dph|iban|swift)", ln, re.IGNORECASE):
+                continue
+            # musí obsahovat aspoň 3 písmena
+            if len(re.findall(r"[A-Za-zÁČĎÉĚÍŇÓŘŠŤÚŮÝŽ]", ln)) < 3:
+                continue
+            return ln[:80].strip()
+        return None
+
+    def _pseudo_ico(self, supplier_name: str) -> str:
+        """Deterministické pseudo-IČO pro retail účtenky bez uvedeného IČO."""
+        import hashlib
+        base = (supplier_name or "UNKNOWN").strip().upper().encode("utf-8", errors="ignore")
+        h = hashlib.sha256(base).hexdigest()[:10]
+        return f"NOICO-{h}"
+        cands = []
+        for m in re.finditer(r"\b\d{8}\b", text):
+            cands.append(m.group(0))
+        # de-dup, stabilní pořadí
+        seen = set()
+        uniq = []
+        for c in cands:
+            if c not in seen:
+                uniq.append(c)
+                seen.add(c)
+
+        valid: List[str] = []
+        for c in uniq[:20]:
+            try:
+                ico_n = normalize_ico(c)
+            except Exception:
+                continue
+            try:
+                # rychlá validace přes ARES
+                fetch_by_ico(ico_n, timeout=4)
+                valid.append(ico_n)
+            except Exception:
+                continue
+            if len(valid) > 1:
+                break
+        if len(valid) == 1:
+            return valid[0]
+        return None
+
+    def process_path(self, session, path: Path, status_cb=None) -> Dict[str, Any]:
+        # returns dict with outcome
+        sha = sha256_file(path)
+        # dedupe check
+        existing = session.execute(
+            text("SELECT id, status FROM files WHERE sha256 = :sha"),
+            {"sha": sha},
+        ).fetchone()
+        if existing:
+            # duplicate file, move to DUPLICITY
+            out_base = Path(self.cfg["paths"]["output_dir"])
+            dup_dir = out_base / self.cfg["paths"].get("duplicate_dir_name", "DUPLICITY")
+            moved = safe_move(path, dup_dir, path.name)
+            return {"status": "DUPLICATE", "sha256": sha, "moved_to": str(moved)}
+
+        if status_cb:
+            status_cb("Začínám vytěžování…")
+
+        # OCR
+        min_conf = float(self.cfg["ocr"].get("min_confidence", 0.65))
+        pages = 1
+        per_doc_chunks: List[Dict[str, Any]] = []
+
+        if path.suffix.lower() == ".pdf":
+            page_texts, page_confs, pages = self._ocr_pdf_pages(path, status_cb=status_cb)
+            if not page_texts:
+                # no text => hard quarantine later
+                page_texts = []
+                page_confs = []
+                pages = 0
+            per_page: List[Tuple[int, Any, str, float]] = []
+            for i, t in enumerate(page_texts, start=1):
+                ex = extract_from_text(t or "")
+                per_page.append((i, ex, t or "", float(page_confs[i - 1] if i - 1 < len(page_confs) else 0.0)))
+            # Merge multi-page invoices deterministically by key
+            per_doc_chunks = self._merge_extracted_by_key(per_page)
+        else:
+            ocr_text, ocr_conf, pages = self._ocr_image(path, status_cb=status_cb)
+            ex = extract_from_text(ocr_text or "")
+            per_doc_chunks = [{
+                "page_from": 1,
+                "page_to": 1,
+                "extracted": ex,
+                "full_text": ocr_text or "",
+                "ocr_conf": float(ocr_conf or 0.0),
+                "key": None,
+            }]
+
+        out_base = Path(self.cfg["paths"]["output_dir"])
+        quarantine_dir = out_base / self.cfg["paths"].get("quarantine_dir_name", "KARANTENA")
+
+        # create file record once (1 file can contain multiple documents)
+        file_record = create_file_record(
+            session,
+            sha256=sha,
+            original_name=path.name,
+            path=str(path),
+            pages=int(pages or 1),
+            status="NEW",
+            mime_type="application/pdf" if path.suffix.lower() == ".pdf" else "image",
+        )
+
+        created_doc_ids: List[int] = []
+        any_requires_review = False
+        any_processed = False
+        method_global = "offline"
+
+        # per-document processing within the file
+        for idx_doc, chunk in enumerate(per_doc_chunks, start=1):
+            if status_cb:
+                status_cb(f"Parsování dokladu {idx_doc}/{max(1, len(per_doc_chunks))}…")
+            extracted = chunk["extracted"]
+            ocr_conf = float(chunk.get("ocr_conf") or 0.0)
+            ocr_text = chunk.get("full_text") or ""
+            page_from = int(chunk.get("page_from") or 1)
+            page_to = int(chunk.get("page_to") or page_from)
+
+            method = "offline"
+            reasons = list(extracted.review_reasons or [])
+
+            # Pokud chybí IČO, zkus heuristiku: najít 8-místné číslo a ověřit v ARES.
+            if not extracted.supplier_ico:
+                guessed_ico = self._guess_supplier_ico_from_text(ocr_text)
+                if guessed_ico:
+                    extracted.supplier_ico = guessed_ico
+                    extracted.confidence = float(max(extracted.confidence or 0.0, 0.80))
+                    reasons.append("IČO doplněno heuristikou (ARES validace)")
+
+
+            # Pokud IČO na dokladu vůbec není (běžné u retail účtenek),
+            # vytvoříme deterministické pseudo-ID dodavatele, aby doklad mohl projít "complete" kontrolou.
+            if not extracted.supplier_ico:
+                supplier_name_guess = self._extract_supplier_name_guess(ocr_text) or "NEZNAMY_DODAVATEL"
+                extracted.supplier_ico = self._pseudo_ico(supplier_name_guess)
+                extracted.confidence = float(max(extracted.confidence or 0.0, 0.75))
+                reasons.append("IČO není na dokladu: použito pseudo-ID dodavatele")
+
+            # Po offline i OpenAI: kanonizace položek (unit_price bez DPH, line_total s DPH) + kontrola součtu.
+            items_ref = list(extracted.items or [])
+            sum_ok, reasons = postprocess_items_for_db(
+                items=items_ref,
+                total_with_vat=extracted.total_with_vat,
+                reasons=reasons,
+            )
+            extracted.items = items_ref
+            extracted.review_reasons = reasons
+
+            # Povinné minimum pro přesun do OUT:
+            # - IČO, číslo dokladu, datum, total (vč. DPH)
+            # - položky
+            # - součet položek (včetně zaokrouhlení) sedí na total v toleranci
+            complete = bool(
+                extracted.supplier_ico
+                and extracted.doc_number
+                and extracted.issue_date
+                and (extracted.total_with_vat is not None)
+                and (len(list(extracted.items or [])) > 0)
+                and sum_ok
+            )
+
+            requires_review = bool((not complete) or (ocr_conf < min_conf))
+            if ocr_conf < min_conf:
+                reasons.append("nízká jistota OCR")
+            if not complete:
+                reasons.append("nekompletní vytěžení")
+
+            # zapiš zpět pro UI/DB konzistenci
+            extracted.requires_review = requires_review
+            # de-dup důvodů, stabilní pořadí
+            extracted.review_reasons = list(dict.fromkeys(reasons))
+
+            supplier_id = None
+            supplier_name_guess: str | None = None
+            if extracted.supplier_ico:
+                # ARES voláme jen pro "skutečné" IČO (číslice). Pro pseudo-IČO nic přes síť neřešíme.
+                if self._looks_like_ico(extracted.supplier_ico):
+                    try:
+                        extracted.supplier_ico = normalize_ico(extracted.supplier_ico)
+                    except Exception:
+                        pass
+                    try:
+                        if status_cb:
+                            status_cb("ARES: doplňuji dodavatele…")
+                        ares = fetch_by_ico(extracted.supplier_ico)
+                        s = upsert_supplier(
+                            session,
+                            ares.ico,
+                            name=ares.name,
+                            dic=ares.dic,
+                            address=ares.address,
+                            is_vat_payer=ares.is_vat_payer,
+                            ares_last_sync=ares.fetched_at,
+                            legal_form=ares.legal_form,
+                            street=ares.street,
+                            street_number=ares.street_number,
+                            orientation_number=ares.orientation_number,
+                            city=ares.city,
+                            zip_code=ares.zip_code,
+                            overwrite=True,
+                        )
+                        supplier_id = s.id
+                        extracted.supplier_ico = ares.ico
+                    except Exception as e:
+                        reasons.append(f"ARES selhal: {e}")
+                        requires_review = True
+                else:
+                    # Pseudo-IČO: uložíme dodavatele lokálně jen se jménem (pokud ho umíme odhadnout).
+                    supplier_name_guess = self._extract_supplier_name_guess(ocr_text)
+                    s = upsert_supplier(
+                        session,
+                        str(extracted.supplier_ico),
+                        name=supplier_name_guess,
+                        overwrite=False,
+                    )
+                    supplier_id = s.id
+
+
+            # Business duplicita per-doc
+            if extracted.supplier_ico and extracted.doc_number and extracted.issue_date:
+                try:
+                    dup = session.execute(
+                        text(
+                            "SELECT id FROM documents "
+                            "WHERE supplier_ico = :ico AND doc_number = :dn AND issue_date = :d "
+                            "LIMIT 1"
+                        ),
+                        {"ico": extracted.supplier_ico, "dn": extracted.doc_number, "d": extracted.issue_date},
+                    ).fetchone()
+                    if dup:
+                        dup_dir = out_base / self.cfg["paths"].get("duplicate_dir_name", "DUPLICITY")
+                        moved = safe_move(path, dup_dir, path.name)
+                        file_record.current_path = str(moved)
+                        file_record.status = "DUPLICATE"
+                        file_record.processed_at = dt.datetime.utcnow()
+                        session.add(file_record)
+                        session.flush()
+                        return {
+                            "status": "DUPLICATE",
+                            "sha256": sha,
+                            "file_id": file_record.id,
+                            "moved_to": str(moved),
+                            "duplicate_of_document_id": int(dup[0]),
+                        }
+                except Exception as e:
+                    reasons.append(f"dup-check selhal: {e}")
+                    requires_review = True
+
+            doc = add_document(
+                session,
+                file_id=file_record.id,
+                supplier_id=supplier_id,
+                supplier_ico=extracted.supplier_ico,
+                doc_number=extracted.doc_number,
+                bank_account=extracted.bank_account,
+                issue_date=extracted.issue_date,
+                total_with_vat=extracted.total_with_vat,
+                currency=extracted.currency,
+                confidence=float(extracted.confidence),
+                method=method,
+                requires_review=requires_review,
+                review_reasons="; ".join(reasons) if reasons else None,
+                items=extracted.items,
+                page_from=page_from,
+                page_to=page_to,
+            )
+            rebuild_fts_for_document(session, doc.id, extracted.full_text if hasattr(extracted, "full_text") else ocr_text)
+            created_doc_ids.append(int(doc.id))
+            any_requires_review = bool(any_requires_review or requires_review)
+            any_processed = True
+
+        # Move file once (based on any_requires_review)
+        out_base = Path(self.cfg["paths"]["output_dir"])
+        quarantine_dir = out_base / self.cfg["paths"].get("quarantine_dir_name", "KARANTENA")
+        if any_requires_review or (not any_processed):
+            moved = safe_move(path, quarantine_dir, path.name)
+            status = "QUARANTINE"
+        else:
+            moved = safe_move(path, out_base, path.name)
+            status = "PROCESSED"
+
+        file_record.current_path = str(moved)
+        file_record.status = status
+        file_record.processed_at = dt.datetime.utcnow()
+        session.add(file_record)
+        session.flush()
+
+        return {
+            "status": status,
+            "sha256": sha,
+            "file_id": file_record.id,
+            "document_ids": created_doc_ids,
+            "moved_to": str(moved),
+        }
diff --git a/src/kajovospend/ui/__pycache__/__init__.cpython-311.pyc b/src/kajovospend/ui/__pycache__/__init__.cpython-311.pyc
new file mode 100644
index 0000000..2b74646
Binary files /dev/null and b/src/kajovospend/ui/__pycache__/__init__.cpython-311.pyc differ
diff --git a/src/kajovospend/ui/__pycache__/db_api.cpython-311.pyc b/src/kajovospend/ui/__pycache__/db_api.cpython-311.pyc
new file mode 100644
index 0000000..34e2ab3
Binary files /dev/null and b/src/kajovospend/ui/__pycache__/db_api.cpython-311.pyc differ
diff --git a/src/kajovospend/ui/__pycache__/main_window.cpython-311.pyc b/src/kajovospend/ui/__pycache__/main_window.cpython-311.pyc
new file mode 100644
index 0000000..24aa2d6
Binary files /dev/null and b/src/kajovospend/ui/__pycache__/main_window.cpython-311.pyc differ
diff --git a/src/kajovospend/ui/__pycache__/styles.cpython-311.pyc b/src/kajovospend/ui/__pycache__/styles.cpython-311.pyc
new file mode 100644
index 0000000..be5ccbd
Binary files /dev/null and b/src/kajovospend/ui/__pycache__/styles.cpython-311.pyc differ
diff --git a/src/kajovospend/ui/db_api.py b/src/kajovospend/ui/db_api.py
index 484bf55..6d9224c 100644
--- a/src/kajovospend/ui/db_api.py
+++ b/src/kajovospend/ui/db_api.py
@@ -3,7 +3,7 @@ from __future__ import annotations
 import datetime as dt
 from typing import Any, Dict, List, Optional, Tuple
 
-from sqlalchemy import select, text, func
+from sqlalchemy import select, text, func, case
 from sqlalchemy.exc import OperationalError
 from sqlalchemy.orm import Session
 
@@ -14,17 +14,193 @@ def counts(session: Session) -> Dict[str, int]:
     unprocessed = session.execute(select(func.count()).select_from(DocumentFile).where(DocumentFile.status == "NEW")).scalar_one()
     processed = session.execute(select(func.count()).select_from(DocumentFile).where(DocumentFile.status == "PROCESSED")).scalar_one()
     quarantine = session.execute(select(func.count()).select_from(DocumentFile).where(DocumentFile.status == "QUARANTINE")).scalar_one()
+    duplicates = session.execute(select(func.count()).select_from(DocumentFile).where(DocumentFile.status == "DUPLICATE")).scalar_one()
     suppliers = session.execute(select(func.count()).select_from(Supplier)).scalar_one()
     docs = session.execute(select(func.count()).select_from(Document)).scalar_one()
     return {
         "unprocessed": int(unprocessed),
         "processed": int(processed),
         "quarantine": int(quarantine),
+        "duplicates": int(duplicates),
         "suppliers": int(suppliers),
         "documents": int(docs),
     }
 
 
+def run_stats(session: Session) -> Dict[str, Any]:
+    """Statistics for RUN tab.
+
+    All indicators are computed strictly from *fully processed* receipts:
+    documents whose underlying file has status PROCESSED.
+    QUARANTINE and DUPLICATE files are excluded from denominators.
+    """
+
+    # base document set = documents that belong to files marked as PROCESSED
+    doc_ids = [
+        int(r[0])
+        for r in session.execute(
+            select(Document.id)
+            .join(DocumentFile, Document.file_id == DocumentFile.id)
+            .where(DocumentFile.status == "PROCESSED")
+        ).all()
+    ]
+
+    total_docs = len(doc_ids)
+    if total_docs == 0:
+        return {
+            "suppliers": 0,
+            "receipts": 0,
+            "items": 0,
+            "pct_offline": 0.0,
+            "pct_api": 0.0,
+            "pct_manual": 0.0,
+            "sum_items_wo_vat": 0.0,
+            "sum_items_w_vat": 0.0,
+            "avg_receipt": 0.0,
+            "avg_item": 0.0,
+            "avg_items_per_receipt": 0.0,
+            "min_items_per_receipt": 0,
+            "max_items_per_receipt": 0,
+            "max_item_price": 0.0,
+            "max_item_name": None,
+        }
+
+    # counts
+    suppliers = int(
+        session.execute(
+            select(func.count(func.distinct(Document.supplier_ico)))
+            .join(DocumentFile, Document.file_id == DocumentFile.id)
+            .where(DocumentFile.status == "PROCESSED")
+            .where(Document.supplier_ico.is_not(None))
+        ).scalar_one()
+        or 0
+    )
+
+    items_count = int(
+        session.execute(select(func.count()).select_from(LineItem).where(LineItem.document_id.in_(doc_ids))).scalar_one()
+        or 0
+    )
+
+    # success by extraction method
+    def _pct(method: str) -> float:
+        n = int(
+            session.execute(
+                select(func.count())
+                .select_from(Document)
+                .where(Document.id.in_(doc_ids))
+                .where(Document.extraction_method == method)
+            ).scalar_one()
+            or 0
+        )
+        return (100.0 * n / total_docs) if total_docs else 0.0
+
+    pct_offline = _pct("offline")
+    pct_api = _pct("openai")
+    pct_manual = _pct("manual")
+
+    # sums and averages over items
+    sum_with_vat = float(
+        session.execute(
+            select(func.sum(LineItem.line_total))
+            .select_from(LineItem)
+            .where(LineItem.document_id.in_(doc_ids))
+        ).scalar_one()
+        or 0.0
+    )
+
+    # best-effort VAT removal; if vat_rate is 0/NULL, treat as already without VAT
+    sum_wo_vat = float(
+        session.execute(
+            select(
+                func.sum(
+                    case(
+                        (
+                            (LineItem.vat_rate.is_(None)) | (LineItem.vat_rate == 0),
+                            LineItem.line_total,
+                        ),
+                        else_=LineItem.line_total / (1.0 + (LineItem.vat_rate / 100.0)),
+                    )
+                )
+            )
+            .select_from(LineItem)
+            .where(LineItem.document_id.in_(doc_ids))
+        ).scalar_one()
+        or 0.0
+    )
+
+    avg_item = float(
+        session.execute(
+            select(func.avg(LineItem.line_total))
+            .select_from(LineItem)
+            .where(LineItem.document_id.in_(doc_ids))
+        ).scalar_one()
+        or 0.0
+    )
+
+    # per-document item counts (for avg/min/max)
+    counts_rows = session.execute(
+        select(LineItem.document_id, func.count(LineItem.id))
+        .select_from(LineItem)
+        .where(LineItem.document_id.in_(doc_ids))
+        .group_by(LineItem.document_id)
+    ).all()
+    per_doc_counts = [int(c or 0) for _doc_id, c in counts_rows]
+    # documents with 0 items (shouldn't happen but keep deterministic)
+    if len(per_doc_counts) < total_docs:
+        per_doc_counts.extend([0] * (total_docs - len(per_doc_counts)))
+
+    avg_items_per_receipt = float(sum(per_doc_counts) / total_docs) if total_docs else 0.0
+    min_items = int(min(per_doc_counts) if per_doc_counts else 0)
+    max_items = int(max(per_doc_counts) if per_doc_counts else 0)
+
+    # average receipt value: prefer Document.total_with_vat, fallback to sum(items)
+    per_doc_sums = {int(did): float(s or 0.0) for did, s in session.execute(
+        select(LineItem.document_id, func.sum(LineItem.line_total))
+        .where(LineItem.document_id.in_(doc_ids))
+        .group_by(LineItem.document_id)
+    ).all()}
+    doc_totals = session.execute(select(Document.id, Document.total_with_vat).where(Document.id.in_(doc_ids))).all()
+    vals = []
+    for did, tv in doc_totals:
+        if tv is not None:
+            vals.append(float(tv))
+        else:
+            vals.append(per_doc_sums.get(int(did), 0.0))
+    avg_receipt = float(sum(vals) / len(vals)) if vals else 0.0
+
+    # max item
+    max_row = session.execute(
+        select(LineItem.name, LineItem.line_total)
+        .select_from(LineItem)
+        .where(LineItem.document_id.in_(doc_ids))
+        .order_by(LineItem.line_total.desc())
+        .limit(1)
+    ).first()
+    max_name = None
+    max_price = 0.0
+    if max_row:
+        max_name = max_row[0]
+        max_price = float(max_row[1] or 0.0)
+
+    return {
+        "suppliers": suppliers,
+        "receipts": total_docs,
+        "items": items_count,
+        "pct_offline": pct_offline,
+        "pct_api": pct_api,
+        "pct_manual": pct_manual,
+        "sum_items_wo_vat": sum_wo_vat,
+        "sum_items_w_vat": sum_with_vat,
+        "avg_receipt": avg_receipt,
+        "avg_item": avg_item,
+        "avg_items_per_receipt": avg_items_per_receipt,
+        "min_items_per_receipt": min_items,
+        "max_items_per_receipt": max_items,
+        "max_item_price": max_price,
+        "max_item_name": max_name,
+    }
+
+
 def list_suppliers(session: Session, q: str = "") -> List[Supplier]:
     stmt = select(Supplier)
     if q.strip():
@@ -200,6 +376,7 @@ def list_documents(
             select(Document, DocumentFile)
             .join(DocumentFile, Document.file_id == DocumentFile.id)
             .where(Document.id.in_(ids))
+            .where(DocumentFile.status != "QUARANTINE")
         )
         # extra safety on date range (even if already applied in FTS)
         stmt = _apply_date_filters(stmt, date_from=date_from, date_to=date_to)
@@ -211,6 +388,7 @@ def list_documents(
     stmt = (
         select(Document, DocumentFile)
         .join(DocumentFile, Document.file_id == DocumentFile.id)
+        .where(DocumentFile.status != "QUARANTINE")
         .order_by(Document.issue_date.desc().nullslast(), Document.id.desc())
     )
     stmt = _apply_date_filters(stmt, date_from=date_from, date_to=date_to)
diff --git a/src/kajovospend/ui/main_window.py b/src/kajovospend/ui/main_window.py
index 13ce518..7cbbc7c 100644
--- a/src/kajovospend/ui/main_window.py
+++ b/src/kajovospend/ui/main_window.py
@@ -1,26 +1,22 @@
 from __future__ import annotations
 
 import datetime as dt
-import functools
 import os
-import subprocess
-import sys
 from io import BytesIO
 from pathlib import Path
 import shutil
 from typing import Any, Dict, List, Optional, Tuple
 
-from PySide6.QtCore import Qt, QTimer, QAbstractTableModel, QModelIndex, QObject, Signal, Slot, QThread, QUrl
-from PySide6.QtGui import QIcon, QPixmap, QImage, QDesktopServices
+from PySide6.QtCore import Qt, QTimer, QAbstractTableModel, QModelIndex, QObject, Signal, Slot, QThread, QUrl, QPointF
+from PySide6.QtGui import QIcon, QPixmap, QImage, QDesktopServices, QPainter, QPen, QColor, QFont
 from PySide6.QtWidgets import (
-    QMainWindow, QWidget, QVBoxLayout, QHBoxLayout, QLabel, QPushButton, QTabWidget, QTableView,
+    QMainWindow, QWidget, QVBoxLayout, QHBoxLayout, QGridLayout, QLabel, QPushButton, QTabWidget, QTableView,
     QLineEdit, QFormLayout, QSplitter, QTextEdit, QDoubleSpinBox, QSpinBox, QComboBox, QFileDialog,
-    QMessageBox, QDateEdit, QProgressBar, QDialog, QDialogButtonBox, QHeaderView, QAbstractItemView,
-    QCheckBox, QProgressDialog, QApplication, QInputDialog,
+    QMessageBox, QDateEdit, QDialog, QDialogButtonBox, QHeaderView, QAbstractItemView,
+    QCheckBox, QProgressDialog, QApplication, QInputDialog, QScrollArea,
 )
 from PySide6.QtWidgets import QGraphicsView, QGraphicsScene, QGraphicsPixmapItem
 
-from sqlalchemy.orm import Session
 from sqlalchemy import select, text
 
 from kajovospend.utils.config import load_yaml, save_yaml, deep_set
@@ -28,11 +24,10 @@ from kajovospend.utils.paths import resolve_app_paths
 from kajovospend.utils.logging_setup import setup_logging
 from kajovospend.db.session import make_engine, make_session_factory
 from kajovospend.db.migrate import init_db
-from kajovospend.db.models import Supplier, Document, DocumentFile, LineItem
+from kajovospend.db.models import Supplier, Document, DocumentFile, LineItem, ImportJob
 from kajovospend.db.queries import upsert_supplier, rebuild_fts_for_document
 from kajovospend.integrations.ares import fetch_by_ico, normalize_ico
-from kajovospend.integrations.openai_fallback import list_models
-from kajovospend.service.control_client import send_cmd
+from kajovospend.service.processor import Processor
 from kajovospend.ocr.pdf_render import render_pdf_to_images
 
 from .styles import QSS
@@ -295,6 +290,72 @@ class _Worker(QObject):
         self.done.emit(res)
 
 
+class _ImportWorker(QObject):
+    progress = Signal(str)
+    done = Signal(dict)
+    error = Signal(str)
+
+    def __init__(self, cfg: Dict[str, Any], sf, processor: Processor):
+        super().__init__()
+        self.cfg = cfg
+        self.sf = sf
+        self.processor = processor
+
+    @Slot()
+    def run(self):
+        try:
+            input_dir = Path(self.cfg["paths"]["input_dir"])
+            if not input_dir.exists():
+                self.done.emit({"imported": 0, "message": "Adresář INPUT neexistuje."})
+                return
+
+            exts = {".pdf", ".png", ".jpg", ".jpeg", ".tif", ".tiff", ".bmp"}
+            files = [p for p in input_dir.iterdir() if p.is_file() and p.suffix.lower() in exts]
+            files.sort(key=lambda p: (p.stat().st_mtime, p.name))
+
+            if not files:
+                self.done.emit({"imported": 0, "message": "V INPUT nejsou žádné soubory."})
+                return
+
+            imported = 0
+            total = len(files)
+
+            for i, p in enumerate(files, start=1):
+                self.progress.emit(f"Zpracovávám {i}/{total}: {p.name}")
+                try:
+                    with self.sf() as session:
+                        job = ImportJob(path=str(p), status="RUNNING", started_at=dt.datetime.utcnow())
+                        session.add(job)
+                        session.commit()
+
+                        res = self.processor.process_path(session, p, status_cb=self.progress.emit)
+                        job.sha256 = res.get("sha256")
+                        job.status = str(res.get("status") or "DONE")
+                        job.finished_at = dt.datetime.utcnow()
+                        session.add(job)
+                        session.commit()
+                        imported += 1
+                except Exception as e:
+                    try:
+                        with self.sf() as session:
+                            job = ImportJob(
+                                path=str(p),
+                                status="ERROR",
+                                started_at=dt.datetime.utcnow(),
+                                finished_at=dt.datetime.utcnow(),
+                                error=str(e),
+                            )
+                            session.add(job)
+                            session.commit()
+                    except Exception:
+                        pass
+                    self.progress.emit(f"Chyba: {p.name}: {e}")
+
+            self.done.emit({"imported": imported, "total": total, "message": "Hotovo."})
+        except Exception as e:
+            self.error.emit(str(e))
+
+
 class _SilentRunner:
     """
     Lightweight background runner (no modal progress).
@@ -391,44 +452,6 @@ class _SilentRunner:
             window._timers.append(timer)
 
 
-class StatusDialog(QDialog):
-    def __init__(self, status: Dict[str, Any], parent=None):
-        super().__init__(parent)
-        self.setWindowTitle("STAV")
-        lay = QVBoxLayout(self)
-        txt = QTextEdit()
-        txt.setReadOnly(True)
-        lines = []
-        keys = [
-            "running",
-            "queue_size",
-            "inflight",
-            "max_workers",
-            "current_phase",
-            "current_progress",
-            "current_job_id",
-            "current_path",
-            "heartbeat_at",
-            "stuck",
-            "stuck_reason",
-            "last_success",
-            "last_error",
-            "last_error_at",
-            "last_seen",
-        ]
-        for k in keys:
-            v = status.get(k)
-            # shorten long paths a bit
-            if k == "current_path" and isinstance(v, str) and len(v) > 140:
-                v = "…" + v[-140:]
-            lines.append(f"{k}: {v}")
-        txt.setText("\n".join(lines))
-        lay.addWidget(txt)
-        bb = QDialogButtonBox(QDialogButtonBox.Ok)
-        bb.accepted.connect(self.accept)
-        lay.addWidget(bb)
-
-
 class SupplierDialog(QDialog):
     def __init__(self, parent=None, initial: Optional[Dict[str, Any]] = None):
         super().__init__(parent)
@@ -512,10 +535,11 @@ class MainWindow(QMainWindow):
         self._preview_cache: Dict[Tuple[str, int], QPixmap] = {}
         self._preview_dpi = int(self.cfg.get("performance", {}).get("preview_dpi", 120) or 120)
 
-        # background dashboard refresh (avoid UI freezes when service is down)
+        # background RUN stats refresh
         self._dash_refresh_inflight = False
         self._dash_last_counts: Dict[str, Any] | None = None
-        self._dash_last_status: Dict[str, Any] | None = None
+        self._import_running = False
+        self._import_status = "Připraveno."
 
         # selection model guards to prevent duplicate signal connections after model resets
         self._docs_sel_model = None
@@ -551,6 +575,7 @@ class MainWindow(QMainWindow):
         self.engine = make_engine(str(self.paths.db_path))
         init_db(self.engine)
         self.sf = make_session_factory(self.engine)
+        self.processor = Processor(self.cfg, self.paths, self.log)
 
         self.setWindowTitle("KájovoSpend")
         ico = self.assets_dir / "app.ico"
@@ -571,7 +596,6 @@ class MainWindow(QMainWindow):
             save_yaml(self.config_path, cfg)
         cfg.setdefault("app", {})
         cfg.setdefault("paths", {})
-        cfg.setdefault("service", {})
         cfg.setdefault("ocr", {})
         cfg.setdefault("openai", {})
         cfg.setdefault("performance", {})
@@ -700,6 +724,137 @@ class MainWindow(QMainWindow):
                 return px
         return None
 
+    def _stat_number_font(self, size: int, *, bold: bool = False) -> QFont:
+        f = QFont()
+        f.setPointSize(int(size))
+        f.setBold(bool(bold))
+        return f
+
+    def _icon_pixmap(self, kind: str, size: int) -> QPixmap:
+        """Create simple monochrome pictograms (no text)."""
+        px = QPixmap(int(size), int(size))
+        px.fill(Qt.transparent)
+
+        p = QPainter(px)
+        p.setRenderHint(QPainter.Antialiasing, True)
+        col = QColor("#E5E7EB")
+        pen = QPen(col)
+        pen.setWidth(max(2, int(size) // 14))
+        pen.setCapStyle(Qt.RoundCap)
+        pen.setJoinStyle(Qt.RoundJoin)
+        p.setPen(pen)
+        p.setBrush(Qt.NoBrush)
+
+        s = float(size)
+        m = s * 0.12
+        x0, y0 = m, m
+        w = s - 2 * m
+        h = s - 2 * m
+
+        def rect(x, y, ww, hh, r=0.0):
+            if r and r > 0:
+                p.drawRoundedRect(int(x), int(y), int(ww), int(hh), float(r), float(r))
+            else:
+                p.drawRect(int(x), int(y), int(ww), int(hh))
+
+        k = (kind or "").lower().strip()
+
+        if k in ("receipt", "doc"):
+            rect(x0, y0, w, h, r=s * 0.08)
+            p.drawLine(int(x0 + w * 0.65), int(y0), int(x0 + w), int(y0 + h * 0.35))
+            p.drawLine(int(x0 + w * 0.65), int(y0), int(x0 + w * 0.65), int(y0 + h * 0.35))
+            p.drawLine(int(x0 + w * 0.65), int(y0 + h * 0.35), int(x0 + w), int(y0 + h * 0.35))
+            for i in range(3):
+                yy = y0 + h * (0.45 + i * 0.16)
+                p.drawLine(int(x0 + w * 0.15), int(yy), int(x0 + w * 0.85), int(yy))
+
+        elif k == "duplicate":
+            rect(x0 + w * 0.14, y0 + h * 0.05, w * 0.78, h * 0.78, r=s * 0.08)
+            rect(x0 + w * 0.05, y0 + h * 0.14, w * 0.78, h * 0.78, r=s * 0.08)
+
+        elif k == "quarantine":
+            p.drawPolygon([
+                QPointF(x0 + w * 0.5, y0),
+                QPointF(x0 + w, y0 + h),
+                QPointF(x0, y0 + h),
+            ])
+            p.drawLine(int(x0 + w * 0.5), int(y0 + h * 0.3), int(x0 + w * 0.5), int(y0 + h * 0.68))
+            p.drawPoint(int(x0 + w * 0.5), int(y0 + h * 0.82))
+
+        elif k == "items":
+            rect(x0, y0, w, h, r=s * 0.08)
+            for i in range(4):
+                yy = y0 + h * (0.2 + i * 0.18)
+                p.drawLine(int(x0 + w * 0.18), int(yy), int(x0 + w * 0.82), int(yy))
+                p.drawPoint(int(x0 + w * 0.12), int(yy))
+
+        elif k == "suppliers":
+            base_y = y0 + h * 0.75
+            p.drawLine(int(x0), int(base_y), int(x0 + w), int(base_y))
+            rect(x0 + w * 0.1, y0 + h * 0.35, w * 0.75, h * 0.4, r=s * 0.05)
+            p.drawLine(int(x0 + w * 0.1), int(y0 + h * 0.35), int(x0 + w * 0.3), int(y0 + h * 0.2))
+            p.drawLine(int(x0 + w * 0.3), int(y0 + h * 0.2), int(x0 + w * 0.5), int(y0 + h * 0.35))
+            p.drawLine(int(x0 + w * 0.5), int(y0 + h * 0.35), int(x0 + w * 0.7), int(y0 + h * 0.2))
+            p.drawLine(int(x0 + w * 0.7), int(y0 + h * 0.2), int(x0 + w * 0.85), int(y0 + h * 0.35))
+            rect(x0 + w * 0.78, y0 + h * 0.12, w * 0.12, h * 0.23, r=s * 0.03)
+
+        elif k == "offline":
+            rect(x0 + w * 0.15, y0 + h * 0.15, w * 0.7, h * 0.7, r=s * 0.1)
+            rect(x0 + w * 0.32, y0 + h * 0.32, w * 0.36, h * 0.36, r=s * 0.06)
+            for i in range(4):
+                xx = x0 + w * (0.22 + i * 0.19)
+                p.drawLine(int(xx), int(y0), int(xx), int(y0 + h * 0.15))
+                p.drawLine(int(xx), int(y0 + h * 0.85), int(xx), int(y0 + h))
+
+        elif k == "api":
+            p.drawEllipse(int(x0 + w * 0.18), int(y0 + h * 0.38), int(w * 0.38), int(h * 0.38))
+            p.drawEllipse(int(x0 + w * 0.38), int(y0 + h * 0.25), int(w * 0.38), int(h * 0.45))
+            p.drawEllipse(int(x0 + w * 0.52), int(y0 + h * 0.4), int(w * 0.34), int(h * 0.34))
+            p.drawLine(int(x0 + w * 0.18), int(y0 + h * 0.62), int(x0 + w * 0.86), int(y0 + h * 0.62))
+
+        elif k == "manual":
+            p.drawLine(int(x0 + w * 0.2), int(y0 + h * 0.8), int(x0 + w * 0.8), int(y0 + h * 0.2))
+            p.drawLine(int(x0 + w * 0.72), int(y0 + h * 0.12), int(x0 + w * 0.88), int(y0 + h * 0.28))
+            p.drawLine(int(x0 + w * 0.12), int(y0 + h * 0.72), int(x0 + w * 0.28), int(y0 + h * 0.88))
+
+        elif k in ("sum_wo_vat", "sum_w_vat", "avg_receipt", "avg_item", "avg_items", "minmax", "max_item"):
+            if k == "minmax":
+                p.drawLine(int(x0 + w * 0.5), int(y0 + h * 0.1), int(x0 + w * 0.5), int(y0 + h * 0.9))
+                p.drawLine(int(x0 + w * 0.35), int(y0 + h * 0.25), int(x0 + w * 0.5), int(y0 + h * 0.1))
+                p.drawLine(int(x0 + w * 0.65), int(y0 + h * 0.25), int(x0 + w * 0.5), int(y0 + h * 0.1))
+                p.drawLine(int(x0 + w * 0.35), int(y0 + h * 0.75), int(x0 + w * 0.5), int(y0 + h * 0.9))
+                p.drawLine(int(x0 + w * 0.65), int(y0 + h * 0.75), int(x0 + w * 0.5), int(y0 + h * 0.9))
+            elif k == "max_item":
+                cx, cy = x0 + w * 0.5, y0 + h * 0.5
+                pts = [
+                    (cx, y0),
+                    (x0 + w * 0.62, y0 + h * 0.38),
+                    (x0 + w, y0 + h * 0.4),
+                    (x0 + w * 0.7, y0 + h * 0.62),
+                    (x0 + w * 0.8, y0 + h),
+                    (cx, y0 + h * 0.78),
+                    (x0 + w * 0.2, y0 + h),
+                    (x0 + w * 0.3, y0 + h * 0.62),
+                    (x0, y0 + h * 0.4),
+                    (x0 + w * 0.38, y0 + h * 0.38),
+                ]
+                p.drawPolygon([QPointF(a, b) for a, b in pts])
+            else:
+                p.drawEllipse(int(x0 + w * 0.15), int(y0 + h * 0.2), int(w * 0.7), int(h * 0.6))
+                p.drawLine(int(x0 + w * 0.2), int(y0 + h * 0.5), int(x0 + w * 0.8), int(y0 + h * 0.5))
+                if k == "sum_w_vat":
+                    p.drawLine(int(x0 + w * 0.5), int(y0 + h * 0.28), int(x0 + w * 0.5), int(y0 + h * 0.72))
+                if k == "avg_item":
+                    p.drawEllipse(int(x0 + w * 0.42), int(y0 + h * 0.38), int(w * 0.16), int(h * 0.16))
+                if k == "avg_receipt":
+                    p.drawRect(int(x0 + w * 0.32), int(y0 + h * 0.28), int(w * 0.36), int(h * 0.44))
+
+        else:
+            p.drawEllipse(int(x0), int(y0), int(w), int(h))
+
+        p.end()
+        return px
+
     def _build_ui(self):
         root = QWidget()
         v = QVBoxLayout(root)
@@ -730,15 +885,9 @@ class MainWindow(QMainWindow):
         hl.addWidget(left)
         hl.addStretch(1)
 
-        self.btn_status = QPushButton("STAV")
-        self.btn_run = QPushButton("RUN")
-        self.btn_stop = QPushButton("STOP")
-        self.btn_restart = QPushButton("RESTART")
         self.btn_exit = QPushButton("EXIT")
         self.btn_exit.setObjectName("ExitButton")
 
-        for b in [self.btn_status, self.btn_run, self.btn_stop, self.btn_restart]:
-            hl.addWidget(b)
         hl.addStretch(1)
         hl.addWidget(self.btn_exit)
 
@@ -747,30 +896,125 @@ class MainWindow(QMainWindow):
         self.tabs = QTabWidget()
         v.addWidget(self.tabs, 1)
 
-        # Dashboard
-        self.tab_dashboard = QWidget()
-        dl = QVBoxLayout(self.tab_dashboard)
-        cards = QWidget()
-        cl = QHBoxLayout(cards)
-        self.lbl_unprocessed = QLabel("Nezpracované: 0")
-        self.lbl_processed = QLabel("Zpracované: 0")
-        self.lbl_docs = QLabel("Účty: 0")
-        self.lbl_suppliers = QLabel("Dodavatelé: 0")
-        for lab in [self.lbl_unprocessed, self.lbl_processed, self.lbl_docs, self.lbl_suppliers]:
-            lab.setMinimumWidth(180)
-            lab.setProperty("card", True)
-            cl.addWidget(lab)
-        cl.addStretch(1)
-        dl.addWidget(cards)
-
-        self.lbl_service = QLabel("Služba: ?")
-        self.progress = QProgressBar()
-        self.progress.setRange(0, 100)
-        self.progress.setValue(0)
-        dl.addWidget(self.lbl_service)
-        dl.addWidget(self.progress)
-
-        self.tabs.addTab(self.tab_dashboard, "DASHBOARD")
+                # RUN
+        self.tab_run = QWidget()
+        rl = QVBoxLayout(self.tab_run)
+
+        split_run = QSplitter(Qt.Vertical)
+        rl.addWidget(split_run, 1)
+
+        # Top half: process info
+        top_run = QWidget()
+        top_run.setObjectName("Panel")
+        trl = QVBoxLayout(top_run)
+
+        row = QWidget()
+        rhl = QHBoxLayout(row)
+        rhl.setContentsMargins(0, 0, 0, 0)
+        rhl.setSpacing(14)
+
+        self.btn_import = QPushButton("IMPORTUJ")
+        self.btn_import.setToolTip("Zařadí soubory z INPUT do fronty zpracování")
+
+        self.lbl_run_status = QLabel(self._import_status)
+        self.lbl_run_status.setWordWrap(True)
+
+        self.ico_quarantine = QLabel()
+        self.ico_quarantine.setPixmap(self._icon_pixmap("quarantine", 26))
+        self.lbl_quarantine_count = QLabel("0")
+        self.lbl_quarantine_count.setFont(self._stat_number_font(14, bold=True))
+        self.ico_quarantine.setToolTip("Počet účtů v karanténě")
+        self.lbl_quarantine_count.setToolTip("Počet účtů v karanténě")
+
+        self.ico_duplicates = QLabel()
+        self.ico_duplicates.setPixmap(self._icon_pixmap("duplicate", 26))
+        self.lbl_duplicates_count = QLabel("0")
+        self.lbl_duplicates_count.setFont(self._stat_number_font(14, bold=True))
+        self.ico_duplicates.setToolTip("Počet duplicitních účtů")
+        self.lbl_duplicates_count.setToolTip("Počet duplicitních účtů")
+
+        rhl.addWidget(self.btn_import)
+        rhl.addWidget(self.lbl_run_status, 1)
+
+        rhl.addWidget(self.ico_quarantine)
+        rhl.addWidget(self.lbl_quarantine_count)
+        rhl.addSpacing(10)
+        rhl.addWidget(self.ico_duplicates)
+        rhl.addWidget(self.lbl_duplicates_count)
+
+        trl.addWidget(row)
+        split_run.addWidget(top_run)
+
+        # Bottom half: stats
+        bottom_run = QWidget()
+        bottom_run.setObjectName("Panel")
+        brl = QVBoxLayout(bottom_run)
+
+        self._stat_labels: Dict[str, QLabel] = {}
+
+        stats_area = QScrollArea()
+        stats_area.setWidgetResizable(True)
+        stats_area.setFrameShape(QScrollArea.NoFrame)
+
+        stats_wrap = QWidget()
+        grid = QGridLayout(stats_wrap)
+        grid.setContentsMargins(8, 8, 8, 8)
+        grid.setHorizontalSpacing(14)
+        grid.setVerticalSpacing(14)
+
+        def add_stat(key: str, icon: str, tooltip: str, row: int, col: int):
+            card = QWidget()
+            card.setObjectName("Panel")
+            hl2 = QHBoxLayout(card)
+            hl2.setContentsMargins(10, 8, 10, 8)
+            hl2.setSpacing(10)
+
+            ico = QLabel()
+            ico.setPixmap(self._icon_pixmap(icon, 48))
+            ico.setToolTip(tooltip)
+
+            val = QLabel("0")
+            val.setObjectName("CardValue")
+            val.setFont(self._stat_number_font(20, bold=True))
+            val.setToolTip(tooltip)
+
+            hl2.addWidget(ico)
+            hl2.addWidget(val, 1)
+
+            self._stat_labels[key] = val
+            grid.addWidget(card, row, col)
+
+        # 13 indicators, arranged 4 columns
+        add_stat("suppliers", "suppliers", "Počet dodavatelů (jen plně vytěžené účty)", 0, 0)
+        add_stat("receipts", "receipt", "Počet účtenek (jen plně vytěžené účty)", 0, 1)
+        add_stat("items", "items", "Počet položek (jen plně vytěžené účty)", 0, 2)
+
+        add_stat("pct_offline", "offline", "% úspěšně vytěžených účtenek offline", 1, 0)
+        add_stat("pct_api", "api", "% úspěšně vytěžených účtenek za pomoci API", 1, 1)
+        add_stat("pct_manual", "manual", "% ručně vytěžených účtenek", 1, 2)
+
+        add_stat("sum_items_wo_vat", "sum_wo_vat", "Celková částka položek bez DPH", 2, 0)
+        add_stat("sum_items_w_vat", "sum_w_vat", "Celková částka položek s DPH", 2, 1)
+        add_stat("avg_receipt", "avg_receipt", "Průměrná cena účtu", 2, 2)
+        add_stat("avg_item", "avg_item", "Průměrná cena položky", 2, 3)
+
+        add_stat("avg_items_per_receipt", "avg_items", "Průměrný počet položek na 1 účet", 3, 0)
+        add_stat("minmax_items_per_receipt", "minmax", "Min a max položek na 1 účtu", 3, 1)
+        add_stat("max_item_price", "max_item", "Nejdražší položka", 3, 2)
+
+        grid.setColumnStretch(0, 1)
+        grid.setColumnStretch(1, 1)
+        grid.setColumnStretch(2, 1)
+        grid.setColumnStretch(3, 1)
+
+        stats_area.setWidget(stats_wrap)
+        brl.addWidget(stats_area, 1)
+
+        split_run.addWidget(bottom_run)
+        split_run.setStretchFactor(0, 1)
+        split_run.setStretchFactor(1, 2)
+
+        self.tabs.addTab(self.tab_run, "RUN")
 
         # Provozní panel
         self.tab_ops = QWidget()
@@ -807,28 +1051,11 @@ class MainWindow(QMainWindow):
         stl = QVBoxLayout(self.tab_settings)
         form = QFormLayout()
 
-        self.ed_api_key = QLineEdit()
-        self.ed_api_key.setPlaceholderText("OpenAI API key")
-        self.cb_model = QComboBox()
-        self.btn_load_models = QPushButton("Načíst modely")
-
         self.ed_input_dir = QLineEdit(self.cfg["paths"].get("input_dir", ""))
         self.btn_pick_input = QPushButton("Vybrat")
         self.ed_output_dir = QLineEdit(self.cfg["paths"].get("output_dir", ""))
         self.btn_pick_output = QPushButton("Vybrat")
 
-        self.cb_openai_enabled = QComboBox()
-        self.cb_openai_enabled.addItems(["false", "true"])
-        self.cb_openai_enabled.setCurrentIndex(1 if self.cfg.get("openai", {}).get("enabled") else 0)
-
-        row_api = QWidget(); r1 = QHBoxLayout(row_api); r1.setContentsMargins(0,0,0,0)
-        r1.addWidget(self.ed_api_key); r1.addWidget(self.cb_openai_enabled)
-        form.addRow("API-KEY / enabled", row_api)
-
-        row_model = QWidget(); r2 = QHBoxLayout(row_model); r2.setContentsMargins(0,0,0,0)
-        r2.addWidget(self.cb_model, 1); r2.addWidget(self.btn_load_models)
-        form.addRow("Model OpenAI", row_model)
-
         row_in = QWidget(); r3 = QHBoxLayout(row_in); r3.setContentsMargins(0,0,0,0)
         r3.addWidget(self.ed_input_dir, 1); r3.addWidget(self.btn_pick_input)
         form.addRow("Input adresář", row_in)
@@ -1145,15 +1372,11 @@ class MainWindow(QMainWindow):
 
         # Actions
         self.btn_exit.clicked.connect(self.close)
-        self.btn_status.clicked.connect(self.on_show_status)
-        self.btn_run.clicked.connect(self.on_run_service)
-        self.btn_stop.clicked.connect(self.on_stop_service)
-        self.btn_restart.clicked.connect(self.on_restart_service)
+        self.btn_import.clicked.connect(self.on_import_clicked)
 
         self.btn_pick_input.clicked.connect(lambda: self._pick_dir(self.ed_input_dir))
         self.btn_pick_output.clicked.connect(lambda: self._pick_dir(self.ed_output_dir))
         self.btn_save_settings.clicked.connect(self.on_save_settings)
-        self.btn_load_models.clicked.connect(self.on_load_models)
 
         self.btn_sup_refresh.clicked.connect(self.refresh_suppliers)
         self._sup_filter_timer.timeout.connect(self.refresh_suppliers)
@@ -1222,7 +1445,7 @@ class MainWindow(QMainWindow):
 
     def _wire_timers(self):
         self.timer = QTimer(self)
-        # Do not refresh too often; otherwise a slow service status poll can starve UI.
+        # Periodic lightweight refresh for RUN tab.
         interval = int(self.cfg.get("performance", {}).get("ui_refresh_ms") or 1000)
         # keep it reasonable even if config is too aggressive
         interval = max(2000, interval)
@@ -2052,86 +2275,111 @@ class MainWindow(QMainWindow):
             except Exception:
                 pass
 
-    def _service_status(self) -> Dict[str, Any]:
+    def on_save_settings(self):
+        deep_set(self.cfg, ["paths", "input_dir"], self.ed_input_dir.text().strip())
+        deep_set(self.cfg, ["paths", "output_dir"], self.ed_output_dir.text().strip())
+        save_yaml(self.config_path, self.cfg)
+        QMessageBox.information(self, "Nastavení", "Uloženo.")
+
+    def _on_import_progress(self, msg: str) -> None:
+        self._import_status = msg
         try:
-            return send_cmd(self.cfg["service"].get("host", "127.0.0.1"), int(self.cfg["service"].get("port", 8765)), "status")
-        except Exception as e:
-            # Never crash UI because the service is down.
-            self.log.warning("service status failed: %s", e)
-            return {
-                "ok": False,
-                "running": False,
-                "queue_size": None,
-                "last_success": None,
-                "last_error": str(e),
-                "last_error_at": dt.datetime.utcnow().isoformat(),
-                "last_seen": None,
-            }
-
-    def _start_service_process(self) -> bool:
-        # Start service as detached process
-        python = sys.executable
-        cmd = [python, str(Path(__file__).resolve().parents[3] / "service_main.py"), "--config", str(self.config_path)]
+            self.lbl_run_status.setText(msg)
+        except Exception:
+            pass
+
+    def _on_import_done(self, res: dict) -> None:
+        imported = int(res.get("imported") or 0)
+        total = int(res.get("total") or imported)
+        msg = str(res.get("message") or "Hotovo.")
+        self._import_status = f"{msg} ({imported}/{total})"
+        self._import_running = False
         try:
-            if os.name == "nt":
-                subprocess.Popen(cmd, creationflags=subprocess.CREATE_NEW_PROCESS_GROUP | subprocess.DETACHED_PROCESS, close_fds=True)
-            else:
-                subprocess.Popen(cmd, start_new_session=True, close_fds=True)
-            return True
-        except Exception as e:
-            QMessageBox.critical(self, "Chyba", f"Nelze spustit službu: {e}")
-            return False
+            self.btn_import.setEnabled(True)
+            self.lbl_run_status.setText(self._import_status)
+        except Exception:
+            pass
 
-    def on_run_service(self):
-        st = self._service_status()
-        if st.get("ok") is not False and st.get("running"):
-            QMessageBox.information(self, "RUN", "Služba už běží.")
+        # refresh views (counts/stats + lists)
+        try:
+            self.refresh_all_v2()
+        except Exception:
+            pass
+        try:
+            self.refresh_ops()
+            self.refresh_suspicious()
+            self.refresh_money()
+        except Exception:
+            pass
+
+    def _on_import_error(self, msg: str) -> None:
+        self._import_running = False
+        self._import_status = f"Chyba: {msg}"
+        try:
+            self.btn_import.setEnabled(True)
+            self.lbl_run_status.setText(self._import_status)
+        except Exception:
+            pass
+        QMessageBox.critical(self, "IMPORTUJ", msg)
+
+    def on_import_clicked(self) -> None:
+        if self._import_running:
             return
-        if self._start_service_process():
-            QMessageBox.information(self, "RUN", "Služba spuštěna.")
+        input_dir_val = self.ed_input_dir.text().strip() or str(self.cfg.get("paths", {}).get("input_dir") or "")
+        if not input_dir_val:
+            QMessageBox.warning(self, "IMPORTUJ", "Není nastaven INPUT adresář (Nastavení → Input adresář).")
+            return
+        output_dir_val = self.ed_output_dir.text().strip() or str(self.cfg.get("paths", {}).get("output_dir") or "")
+        deep_set(self.cfg, ["paths", "input_dir"], input_dir_val)
+        if output_dir_val:
+            deep_set(self.cfg, ["paths", "output_dir"], output_dir_val)
 
-    def on_stop_service(self):
+        self._import_running = True
+        self._import_status = "Načítám INPUT…"
         try:
-            send_cmd(self.cfg["service"].get("host", "127.0.0.1"), int(self.cfg["service"].get("port", 8765)), "stop")
-        except Exception as e:
-            # Stop should not crash if service is already down.
-            QMessageBox.warning(self, "STOP", f"Službu se nepodařilo zastavit (možná neběží): {e}")
+            self.btn_import.setEnabled(False)
+            self.lbl_run_status.setText(self._import_status)
+        except Exception:
+            pass
 
-    def on_restart_service(self):
-        self.on_stop_service()
-        QTimer.singleShot(800, self.on_run_service)
+        th = QThread(self)
+        wk = _ImportWorker(self.cfg, self.sf, self.processor)
+        wk.moveToThread(th)
+        th.started.connect(wk.run)
+        wk.progress.connect(self._on_import_progress)
+        wk.done.connect(self._on_import_done)
+        wk.error.connect(self._on_import_error)
 
-    def on_show_status(self):
-        # avoid blocking UI if service is down (socket timeout)
-        def work():
-            return self._service_status()
-        def done(st):
-            d = StatusDialog(st, self)
-            d.exec()
-        self._run_with_busy("STAV", "Načítám stav služby…", work, done, timeout_ms=8000)
+        cleaned = False
 
-    def on_save_settings(self):
-        deep_set(self.cfg, ["paths", "input_dir"], self.ed_input_dir.text().strip())
-        deep_set(self.cfg, ["paths", "output_dir"], self.ed_output_dir.text().strip())
-        enabled = self.cb_openai_enabled.currentText().lower() == "true"
-        deep_set(self.cfg, ["openai", "enabled"], enabled)
-        deep_set(self.cfg, ["openai", "api_key"], self.ed_api_key.text().strip())
-        deep_set(self.cfg, ["openai", "model"], self.cb_model.currentText().strip())
-        save_yaml(self.config_path, self.cfg)
-        QMessageBox.information(self, "Nastavení", "Uloženo.")
+        def _cleanup_thread():
+            nonlocal cleaned
+            if cleaned:
+                return
+            cleaned = True
+            try:
+                th.quit()
+                th.wait(2000)
+            except Exception:
+                pass
+            try:
+                self._threads.remove(th)
+            except Exception:
+                pass
+            try:
+                self._workers.remove(wk)
+            except Exception:
+                pass
 
-    def on_load_models(self):
-        api_key = self.ed_api_key.text().strip() or str(self.cfg.get("openai", {}).get("api_key") or "")
-        if not api_key:
-            QMessageBox.warning(self, "Modely", "Nejdřív zadej API-KEY.")
-            return
-        def work():
-            return list_models(api_key)
-        def done(models: List[str]):
-            self.cb_model.clear()
-            self.cb_model.addItems(models)
-            QMessageBox.information(self, "Modely", f"Načteno: {len(models)}")
-        self._run_with_busy("Modely", "Načítám dostupné modely…", work, done)
+        wk.done.connect(lambda _res: _cleanup_thread())
+        wk.error.connect(lambda _msg: _cleanup_thread())
+        th.finished.connect(_cleanup_thread)
+
+        # Keep references alive
+        self._threads.append(th)
+        self._workers.append(wk)  # type: ignore
+
+        th.start()
 
     def refresh_all(self):
         self.refresh_dashboard()
@@ -2146,57 +2394,99 @@ class MainWindow(QMainWindow):
         # Keep API compatibility, but do not block UI thread.
         self._refresh_dashboard_async()
 
-    def _apply_dashboard(self, c: Dict[str, Any] | None, st: Dict[str, Any] | None) -> None:
+    def _apply_dashboard(self, c: Dict[str, Any] | None, rs: Dict[str, Any] | None) -> None:
+        try:
+            self.lbl_run_status.setText(self._import_status)
+        except Exception:
+            pass
+
         if c:
             try:
-                self.lbl_unprocessed.setText(f"Nezpracované: {c.get('unprocessed', 0)}")
-                self.lbl_processed.setText(f"Zpracované: {c.get('processed', 0)}")
-                self.lbl_docs.setText(f"Účty: {c.get('documents', 0)}")
-                self.lbl_suppliers.setText(f"Dodavatelé: {c.get('suppliers', 0)}")
-            except Exception:
-                pass
-        if st:
-            try:
-                running = bool(st.get("running"))
-                self.lbl_service.setText(
-                    f"Služba: {'běží' if running else 'neběží'} | fronta: {st.get('queue_size')}"
-                )
-                qsz = st.get("queue_size") or 0
-                self.progress.setValue(0 if qsz == 0 else min(95, int(100 / (qsz + 1))))
+                self.lbl_quarantine_count.setText(str(int(c.get("quarantine", 0) or 0)))
+                self.lbl_duplicates_count.setText(str(int(c.get("duplicates", 0) or 0)))
             except Exception:
                 pass
 
+        if not rs:
+            return
+
+        def fmt_int(n: int) -> str:
+            return f"{int(n):,}".replace(",", " ")
+
+        def fmt_money(x: float) -> str:
+            return f"{float(x):,.2f}".replace(",", " ")
+
+        def fmt_pct(x: float) -> str:
+            return f"{float(x):.1f} %"
+
+        try:
+            if "suppliers" in self._stat_labels:
+                self._stat_labels["suppliers"].setText(fmt_int(rs.get("suppliers", 0) or 0))
+            if "receipts" in self._stat_labels:
+                self._stat_labels["receipts"].setText(fmt_int(rs.get("receipts", 0) or 0))
+            if "items" in self._stat_labels:
+                self._stat_labels["items"].setText(fmt_int(rs.get("items", 0) or 0))
+
+            if "pct_offline" in self._stat_labels:
+                self._stat_labels["pct_offline"].setText(fmt_pct(rs.get("pct_offline", 0.0) or 0.0))
+            if "pct_api" in self._stat_labels:
+                self._stat_labels["pct_api"].setText(fmt_pct(rs.get("pct_api", 0.0) or 0.0))
+            if "pct_manual" in self._stat_labels:
+                self._stat_labels["pct_manual"].setText(fmt_pct(rs.get("pct_manual", 0.0) or 0.0))
+
+            if "sum_items_wo_vat" in self._stat_labels:
+                self._stat_labels["sum_items_wo_vat"].setText(fmt_money(rs.get("sum_items_wo_vat", 0.0) or 0.0))
+            if "sum_items_w_vat" in self._stat_labels:
+                self._stat_labels["sum_items_w_vat"].setText(fmt_money(rs.get("sum_items_w_vat", 0.0) or 0.0))
+            if "avg_receipt" in self._stat_labels:
+                self._stat_labels["avg_receipt"].setText(fmt_money(rs.get("avg_receipt", 0.0) or 0.0))
+            if "avg_item" in self._stat_labels:
+                self._stat_labels["avg_item"].setText(fmt_money(rs.get("avg_item", 0.0) or 0.0))
+
+            if "avg_items_per_receipt" in self._stat_labels:
+                self._stat_labels["avg_items_per_receipt"].setText(f"{float(rs.get('avg_items_per_receipt', 0.0) or 0.0):.2f}")
+
+            if "minmax_items_per_receipt" in self._stat_labels:
+                mi = int(rs.get("min_items_per_receipt", 0) or 0)
+                ma = int(rs.get("max_items_per_receipt", 0) or 0)
+                self._stat_labels["minmax_items_per_receipt"].setText(f"{mi}–{ma}")
+
+            if "max_item_price" in self._stat_labels:
+                mx = float(rs.get("max_item_price", 0.0) or 0.0)
+                self._stat_labels["max_item_price"].setText(fmt_money(mx))
+                nm = rs.get("max_item_name")
+                if nm:
+                    self._stat_labels["max_item_price"].setToolTip(f"Nejdražší položka: {nm}")
+        except Exception:
+            pass
+
     def _refresh_dashboard_async(self) -> None:
-        # prevent overlapping refreshes (important when service status is slow)
+        # prevent overlapping refreshes
         if self._dash_refresh_inflight:
             return
         self._dash_refresh_inflight = True
 
         def work():
             c = None
-            st = None
+            rs = None
             try:
                 with self.sf() as session:
                     c = db_api.counts(session)
+                    rs = db_api.run_stats(session)
             except Exception as e:
                 c = None
+                rs = None
                 try:
-                    self.log.debug("dashboard counts failed: %s", e)
+                    self.log.debug("run tab stats failed: %s", e)
                 except Exception:
                     pass
-            try:
-                # This may block up to socket timeout, but it's in background thread.
-                st = self._service_status()
-            except Exception as e:
-                st = {"ok": False, "running": False, "queue_size": None, "error": str(e)}
-            return (c, st)
+            return (c, rs)
 
         def done(res):
             try:
-                c, st = res
+                c, rs = res
                 self._dash_last_counts = c
-                self._dash_last_status = st
-                self._apply_dashboard(c, st)
+                self._apply_dashboard(c, rs)
             finally:
                 self._dash_refresh_inflight = False
 
diff --git a/src/kajovospend/utils/__pycache__/__init__.cpython-311.pyc b/src/kajovospend/utils/__pycache__/__init__.cpython-311.pyc
new file mode 100644
index 0000000..a2dcb12
Binary files /dev/null and b/src/kajovospend/utils/__pycache__/__init__.cpython-311.pyc differ
diff --git a/src/kajovospend/utils/__pycache__/config.cpython-311.pyc b/src/kajovospend/utils/__pycache__/config.cpython-311.pyc
new file mode 100644
index 0000000..a3aca7b
Binary files /dev/null and b/src/kajovospend/utils/__pycache__/config.cpython-311.pyc differ
diff --git a/src/kajovospend/utils/__pycache__/hashing.cpython-311.pyc b/src/kajovospend/utils/__pycache__/hashing.cpython-311.pyc
new file mode 100644
index 0000000..7c8faa6
Binary files /dev/null and b/src/kajovospend/utils/__pycache__/hashing.cpython-311.pyc differ
diff --git a/src/kajovospend/utils/__pycache__/logging_setup.cpython-311.pyc b/src/kajovospend/utils/__pycache__/logging_setup.cpython-311.pyc
new file mode 100644
index 0000000..4f7bad5
Binary files /dev/null and b/src/kajovospend/utils/__pycache__/logging_setup.cpython-311.pyc differ
diff --git a/src/kajovospend/utils/__pycache__/paths.cpython-311.pyc b/src/kajovospend/utils/__pycache__/paths.cpython-311.pyc
new file mode 100644
index 0000000..79c458d
Binary files /dev/null and b/src/kajovospend/utils/__pycache__/paths.cpython-311.pyc differ
