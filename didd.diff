diff --git a/src/kajovospend/db/migrate.py b/src/kajovospend/db/migrate.py
index 8a6f4d2..b4e0d4e 100644
--- a/src/kajovospend/db/migrate.py
+++ b/src/kajovospend/db/migrate.py
@@ -1,6 +1,7 @@
 from __future__ import annotations
 
 import re
+from typing import Set
 from sqlalchemy import text
 from sqlalchemy.engine import Engine
 
@@ -73,6 +74,7 @@ def _ensure_columns_and_indexes(engine: Engine) -> None:
         # documents: newly added paging metadata
         cols_docs = con.execute(text("PRAGMA table_info('documents')")).fetchall()
         doc_col_names = {row[1] for row in cols_docs}
         if "page_from" not in doc_col_names:
             con.execute(text("ALTER TABLE documents ADD COLUMN page_from INTEGER DEFAULT 1"))
         if "page_to" not in doc_col_names:
             con.execute(text("ALTER TABLE documents ADD COLUMN page_to INTEGER"))
+        # documents: audit columns for text quality + OpenAI fallback (even if OpenAI not wired yet)
+        if "document_text_quality" not in doc_col_names:
+            con.execute(text("ALTER TABLE documents ADD COLUMN document_text_quality REAL DEFAULT 0.0"))
+        if "openai_model" not in doc_col_names:
+            con.execute(text("ALTER TABLE documents ADD COLUMN openai_model TEXT"))
+        if "openai_raw_response" not in doc_col_names:
+            con.execute(text("ALTER TABLE documents ADD COLUMN openai_raw_response TEXT"))
 
         # items: UI expects unit_price/ean/item_code
         cols_items = con.execute(text("PRAGMA table_info('items')")).fetchall()
         item_col_names = {row[1] for row in cols_items}
@@ -128,6 +130,9 @@ def _ensure_columns_and_indexes(engine: Engine) -> None:
         con.execute(text("CREATE INDEX IF NOT EXISTS idx_documents_requires_review ON documents(requires_review)"))
         con.execute(text("CREATE INDEX IF NOT EXISTS idx_documents_file_page ON documents(file_id, page_from, page_to)"))
         # Kompozitní index pro business duplicity (IČO + číslo dokladu + datum).
         con.execute(text("CREATE INDEX IF NOT EXISTS idx_documents_dup_key ON documents(supplier_ico, doc_number, issue_date)"))
+        # Audit / debug
+        con.execute(text("CREATE INDEX IF NOT EXISTS idx_documents_text_quality ON documents(document_text_quality)"))
+        con.execute(text("CREATE INDEX IF NOT EXISTS idx_documents_extraction_method ON documents(extraction_method)"))
 
         # Line items foreign key / filtering
         con.execute(text("CREATE INDEX IF NOT EXISTS idx_line_items_document_id ON items(document_id)"))
         con.execute(text("CREATE INDEX IF NOT EXISTS idx_line_items_name ON items(name)"))
diff --git a/src/kajovospend/db/models.py b/src/kajovospend/db/models.py
index 4aa59cc..a8e9f80 100644
--- a/src/kajovospend/db/models.py
+++ b/src/kajovospend/db/models.py
@@ -1,7 +1,7 @@
 from __future__ import annotations
 
 import datetime as dt
-from sqlalchemy import Boolean, Date, DateTime, Float, ForeignKey, Integer, String, Text, UniqueConstraint, Index
+from sqlalchemy import Boolean, Date, DateTime, Float, ForeignKey, Integer, String, Text, UniqueConstraint, Index
 from sqlalchemy.orm import Mapped, mapped_column, relationship
 from typing import List
 
 from .base import Base
@@ -72,6 +72,10 @@ class Document(Base):
 
     extraction_confidence: Mapped[float] = mapped_column(Float, default=0.0)
     extraction_method: Mapped[str] = mapped_column(String(16), default="offline")  # offline/openai/manual
+    # aggregated quality of chosen per-page text (0..1)
+    document_text_quality: Mapped[float] = mapped_column(Float, default=0.0)
+    openai_model: Mapped[str | None] = mapped_column(String(64), nullable=True)
+    openai_raw_response: Mapped[str | None] = mapped_column(Text, nullable=True)
     requires_review: Mapped[bool] = mapped_column(Boolean, default=False)
     review_reasons: Mapped[str | None] = mapped_column(Text, nullable=True)
 
@@ -87,6 +91,38 @@ class Document(Base):
         Index("ix_documents_file_page", "file_id", "page_from", "page_to"),
     )
 
+
+class DocumentPageAudit(Base):
+    __tablename__ = "document_page_audit"
+
+    id: Mapped[int] = mapped_column(Integer, primary_key=True)
+    document_id: Mapped[int] = mapped_column(ForeignKey("documents.id", ondelete="CASCADE"), index=True)
+    file_id: Mapped[int] = mapped_column(ForeignKey("files.id", ondelete="CASCADE"), index=True)
+
+    page_no: Mapped[int] = mapped_column(Integer)  # 1-based
+    chosen_mode: Mapped[str] = mapped_column(String(16))  # embedded/ocr
+
+    chosen_score: Mapped[float] = mapped_column(Float, default=0.0)
+    embedded_score: Mapped[float] = mapped_column(Float, default=0.0)
+    ocr_score: Mapped[float] = mapped_column(Float, default=0.0)
+
+    embedded_len: Mapped[int] = mapped_column(Integer, default=0)
+    ocr_len: Mapped[int] = mapped_column(Integer, default=0)
+    ocr_conf: Mapped[float] = mapped_column(Float, default=0.0)
+    token_groups: Mapped[int] = mapped_column(Integer, default=0)
+
+    __table_args__ = (
+        UniqueConstraint("document_id", "page_no", name="uq_page_audit_doc_page"),
+        Index("ix_page_audit_file_page", "file_id", "page_no"),
+    )
+
+
 class LineItem(Base):
     __tablename__ = "items"
 
diff --git a/src/kajovospend/utils/text_quality.py b/src/kajovospend/utils/text_quality.py
index 6f49c7a..cc40f50 100644
--- a/src/kajovospend/utils/text_quality.py
+++ b/src/kajovospend/utils/text_quality.py
@@ -1,6 +1,173 @@
 from __future__ import annotations
 
-from typing import Any, Dict, List
+import re
+import string
+import unicodedata
+from typing import Any, Dict, List, Tuple
+
+_AMOUNT_RE = re.compile(r"\b\d{1,6}(?:[ \u00a0]\d{3})*(?:[.,]\d{2})\b")
+
+_TOKEN_GROUPS = [
+    # G1 currency / money
+    ("kč", "kc", "czk", "eur", "usd"),
+    # G2 totals
+    ("celkem", "k úhradě", "součet", "total"),
+    # G3 identification
+    ("ičo", "ico", "dič", "dic"),
+    # G4 dates-ish
+    ("datum", "vystaven", "splatn", "duzp", "zdanit"),
+    # G5 doc type
+    ("faktura", "daňový doklad", "uctenka", "účtenka", "pokladna", "prodej", "paragon"),
+]
+
+
+def _clamp(x: float) -> float:
+    return 0.0 if x < 0.0 else 1.0 if x > 1.0 else float(x)
+
+
+def text_quality_score(text: str) -> Tuple[float, Dict[str, Any]]:
+    """
+    Deterministické skóre kvality textu (0..1) dle pevné specifikace.
+    Vrací: (score, metrics) kde metrics obsahuje i dílčí složky pro audit/debug.
+    """
+    t = (text or "").replace("\xa0", " ").strip()
+    N = len(t)
+    if N == 0:
+        return 0.0, {
+            "N": 0,
+            "token_groups": 0,
+            "amount_matches": 0,
+            "lines": 0,
+            "score": 0.0,
+        }
+
+    non_ws = 0
+    alnum = 0
+    punct = 0
+    ctrl = 0
+    repl = t.count("\ufffd")
+
+    for ch in t:
+        if ch.isspace():
+            continue
+        non_ws += 1
+        if ch.isalnum():
+            alnum += 1
+        cat = unicodedata.category(ch)
+        if cat.startswith("P") or ch in string.punctuation:
+            punct += 1
+        if cat.startswith("C") and ch not in "\t\n\r":
+            ctrl += 1
+
+    ctrl += repl
+    whitespace = N - non_ws
+
+    alnum_ratio = alnum / max(1, non_ws)
+    whitespace_ratio = whitespace / max(1, N)
+    punct_ratio = punct / max(1, non_ws)
+
+    lower = t.lower()
+    token_groups = 0
+    for grp in _TOKEN_GROUPS:
+        if any(tok in lower for tok in grp):
+            token_groups += 1
+
+    amount_matches = len(_AMOUNT_RE.findall(t))
+    lines = sum(1 for ln in t.splitlines() if ln.strip())
+
+    # max non-space run
+    max_run = 0
+    for m in re.finditer(r"\S+", t):
+        ml = len(m.group(0))
+        if ml > max_run:
+            max_run = ml
+
+    # components 0..1 (pevné transformace)
+    c_len = _clamp(N / 600.0)
+    c_alnum = _clamp((alnum_ratio - 0.45) / 0.35)
+    c_space = _clamp(1.0 - (abs(whitespace_ratio - 0.22) / 0.22))
+    c_tokens = _clamp(token_groups / 3.0)
+    c_amounts = _clamp(amount_matches / 3.0)
+    c_lines = _clamp(lines / 10.0)
+
+    # penalties 0..1 (pevné transformace)
+    p_ctrl = _clamp(ctrl / 3.0)
+    p_run = _clamp((max_run - 40.0) / 60.0)
+    p_punct = _clamp((punct_ratio - 0.25) / 0.25)
+
+    positives = (
+        0.15 * c_len
+        + 0.25 * c_alnum
+        + 0.15 * c_space
+        + 0.20 * c_tokens
+        + 0.10 * c_amounts
+        + 0.15 * c_lines
+    )
+    penalties = (0.20 * p_ctrl) + (0.20 * p_run) + (0.15 * p_punct)
+    score = _clamp(positives - penalties)
+
+    metrics: Dict[str, Any] = {
+        "N": N,
+        "non_ws": non_ws,
+        "alnum_ratio": alnum_ratio,
+        "whitespace_ratio": whitespace_ratio,
+        "punct_ratio": punct_ratio,
+        "token_groups": token_groups,
+        "amount_matches": amount_matches,
+        "lines": lines,
+        "ctrl": ctrl,
+        "max_run": max_run,
+        "c_len": c_len,
+        "c_alnum": c_alnum,
+        "c_space": c_space,
+        "c_tokens": c_tokens,
+        "c_amounts": c_amounts,
+        "c_lines": c_lines,
+        "p_ctrl": p_ctrl,
+        "p_run": p_run,
+        "p_punct": p_punct,
+        "positives": positives,
+        "penalties": penalties,
+        "score": score,
+    }
+    return score, metrics
 
 
 def compute_text_quality(text: str) -> Dict[str, Any]:
     t = text or ""
@@ -74,6 +241,7 @@ def summarize_text_quality(metrics: List[Dict[str, Any]]) -> Dict[str, Any]:
         "avg_line_len": float(avg_line_len),
     }
diff --git a/src/kajovospend/service/processor.py b/src/kajovospend/service/processor.py
index 1e60fa1..ad6f0f3 100644
--- a/src/kajovospend/service/processor.py
+++ b/src/kajovospend/service/processor.py
@@ -13,7 +13,7 @@ from pypdf import PdfReader
 from sqlalchemy import text
 
 from kajovospend.db.models import ImportJob
 from kajovospend.db.queries import (
@@ -29,7 +29,7 @@ from kajovospend.integrations.ares import fetch_by_ico, normalize_ico
 from kajovospend.ocr.pdf_render import render_pdf_to_images
 from kajovospend.ocr.rapidocr_engine import RapidOcrEngine
 from kajovospend.utils.hashing import sha256_file
-from kajovospend.utils.text_quality import compute_text_quality, summarize_text_quality
+from kajovospend.utils.text_quality import compute_text_quality, summarize_text_quality, text_quality_score
 
 
 def safe_move(src: Path, dst_dir: Path, target_name: str) -> Path:
@@ -57,7 +57,7 @@ class Processor:
             self.log.warning(f"OCR init failed; will quarantine documents. Error: {e}")
             self.ocr_engine = None
 
-    def _ocr_pdf_pages(self, pdf_path: Path, status_cb=None) -> Tuple[List[str], List[float], int, str, Dict[str, Any]]:
+    def _ocr_pdf_pages(self, pdf_path: Path, status_cb=None) -> Tuple[List[str], List[float], int, str, Dict[str, Any]]:
         """
         Hybrid per-page OCR:
         - pro každou stránku nejdřív zkus embedded text (extract_text), ohodnoť kvalitu
@@ -69,76 +69,37 @@ class Processor:
         text_method = "pdf_hybrid"
         text_debug: Dict[str, Any] = {"path": str(pdf_path)}
 
-        ocr_cfg = (self.cfg.get("ocr") or {}) if isinstance(self.cfg, dict) else {}
-        quality_threshold = float(ocr_cfg.get("page_text_quality_threshold", 0.45))
-        min_non_ws = int(ocr_cfg.get("page_text_min_non_ws", 25))
-        score_margin = float(ocr_cfg.get("page_text_score_margin", 0.02))
-
-        def _metrics(txt: str) -> Dict[str, Any]:
-            t = txt or ""
-            total = len(t)
-            non_ws = len(re.sub(r"\s+", "", t))
-            letters = len(re.findall(r"[A-Za-zÁČĎÉĚÍŇÓŘŠŤÚŮÝŽáčďéěíňóřšťúůýž]", t))
-            digits = len(re.findall(r"\d", t))
-            bad = t.count("\ufffd") + len(re.findall(r"[\x00-\x08\x0b\x0c\x0e-\x1f]", t))
-            lines_nonempty = len([ln for ln in t.splitlines() if ln.strip()])
-            return {
-                "total": total,
-                "non_ws": non_ws,
-                "letters": letters,
-                "digits": digits,
-                "bad": bad,
-                "lines_nonempty": lines_nonempty,
-            }
-
-        def _score(m: Dict[str, Any]) -> float:
-            total = int(m.get("total") or 0)
-            non_ws = int(m.get("non_ws") or 0)
-            if non_ws <= 0 or total <= 0:
-                return 0.0
-            letters = int(m.get("letters") or 0)
-            digits = int(m.get("digits") or 0)
-            bad = int(m.get("bad") or 0)
-            density = min(1.0, non_ws / 400.0)
-            alnum_ratio = (letters + digits) / max(1, non_ws)
-            bad_ratio = bad / max(1, total)
-            s = 0.55 * density + 0.55 * alnum_ratio - 0.80 * bad_ratio
-            if s < 0.0:
-                return 0.0
-            if s > 1.0:
-                return 1.0
-            return float(s)
-
-        def _conf_from_embedded(m: Dict[str, Any], s: float) -> float:
-            non_ws = int(m.get("non_ws") or 0)
-            if non_ws <= 0:
-                return 0.0
-            conf = 0.50 + 0.45 * float(s)
-            if conf < 0.0:
-                conf = 0.0
-            if conf > 0.95:
-                conf = 0.95
-            return float(conf)
+        ocr_cfg = (self.cfg.get("ocr") or {}) if isinstance(self.cfg, dict) else {}
+        # Spec defaults: trigger OCR if score < 0.35 or len(text) < 120
+        quality_threshold = float(ocr_cfg.get("page_text_quality_threshold", 0.35))
+        min_len = int(ocr_cfg.get("page_text_min_len", 120))
+        score_margin = float(ocr_cfg.get("page_text_score_margin", 0.02))
+
+        def _conf_from_score(s: float) -> float:
+            # keep deterministic bounded mapping; never claim 0.95 for garbage text
+            conf = 0.50 + 0.45 * float(s)
+            if conf < 0.0:
+                conf = 0.0
+            if conf > 0.95:
+                conf = 0.95
+            return float(conf)
 
         if status_cb:
             status_cb("PDF: čtu text (hybrid embedded/OCR)…")
 
         try:
             reader = PdfReader(str(pdf_path))
             embedded_texts: List[str] = []
-            embedded_metrics: List[Dict[str, Any]] = []
             embedded_scores: List[float] = []
+            embedded_token_groups: List[int] = []
             for page in reader.pages:
                 t = page.extract_text() or ""
                 embedded_texts.append(t)
-                m = _metrics(t)
-                embedded_metrics.append(m)
-                embedded_scores.append(_score(m))
+                s, met = text_quality_score(t)
+                embedded_scores.append(float(s))
+                embedded_token_groups.append(int(met.get("token_groups") or 0))
             n_pages = len(embedded_texts)
             text_debug["embedded_scores"] = embedded_scores
             if n_pages > 0:
@@ -152,12 +113,12 @@ class Processor:
         except Exception as e:
             self.log.warning(f"PDF embedded extract_text() failed; fallback to OCR. Error: {e}")
             embedded_texts = []
-            embedded_metrics = []
             embedded_scores = []
+            embedded_token_groups = []
             n_pages = 0
             text_debug["embedded_error"] = str(e)
 
         if n_pages <= 0 and self.ocr_engine is None:
@@ -166,30 +127,41 @@ class Processor:
             return [], [], 0, "none", text_debug
 
         needs_ocr: List[bool] = []
         if n_pages > 0:
             for i in range(n_pages):
-                m = embedded_metrics[i]
                 s = embedded_scores[i]
-                weak = (int(m.get("non_ws") or 0) < min_non_ws) or (float(s) < quality_threshold)
+                t = embedded_texts[i] or ""
+                weak = (len(t) < min_len) or (float(s) < quality_threshold)
                 needs_ocr.append(bool(weak))
 
         out_texts: List[str] = list(embedded_texts) if embedded_texts else []
         out_confs: List[float] = []
+        page_audit: List[Dict[str, Any]] = []
         if embedded_texts:
             for i in range(n_pages):
-                out_confs.append(_conf_from_embedded(embedded_metrics[i], embedded_scores[i]))
+                out_confs.append(_conf_from_score(embedded_scores[i]))
 
         if embedded_texts:
             weak_cnt = sum(1 for x in needs_ocr if x)
             text_debug["weak_pages"] = weak_cnt
             self.log.info(
                 f"pdf_text_source: pages={n_pages} weak_pages={weak_cnt} "
-                f"threshold={quality_threshold:.2f} min_non_ws={min_non_ws}"
+                f"threshold={quality_threshold:.2f} min_len={min_len}"
             )
 
         if self.ocr_engine is None:
             if embedded_texts:
                 text_debug["method"] = "embedded"
                 for i in range(n_pages):
-                    m = embedded_metrics[i]
                     s = embedded_scores[i]
                     chosen = "embedded"
                     why = "weak_embedded_but_no_ocr" if needs_ocr[i] else "embedded_ok"
+                    page_audit.append({
+                        "page_no": i + 1,
+                        "chosen_mode": "embedded",
+                        "chosen_score": float(s),
+                        "embedded_score": float(s),
+                        "ocr_score": 0.0,
+                        "embedded_len": len(embedded_texts[i] or ""),
+                        "ocr_len": 0,
+                        "ocr_conf": 0.0,
+                        "token_groups": int(embedded_token_groups[i] or 0),
+                    })
                     self.log.info(
                         f"pdf_text_source page={i+1}/{n_pages} chosen={chosen} why={why} "
-                        f"emb_score={s:.3f} emb_nonws={int(m.get('non_ws') or 0)} emb_bad={int(m.get('bad') or 0)}"
+                        f"emb_score={s:.3f} emb_len={len(embedded_texts[i] or '')} token_groups={int(embedded_token_groups[i] or 0)}"
                     )
                 text_method = "embedded"
+                text_debug["page_audit"] = page_audit
                 return out_texts, out_confs, n_pages, text_method, text_debug
             text_debug["reason"] = "no_ocr_engine"
             text_debug["method"] = "none"
             return [], [], 0, "none", text_debug
 
         dpi_cfg = int(self.cfg["ocr"].get("pdf_dpi", 200))
         dpi = max(300, dpi_cfg)
         text_debug["dpi"] = dpi
@@ -206,6 +178,8 @@ class Processor:
             confs2: List[float] = []
             for idx_page, img in enumerate(images, start=1):
                 if status_cb:
                     status_cb(f"OCR: strana {idx_page}/{len(images)}…")
                 t, c = self.ocr_engine.image_to_text(img)
                 texts2.append(t or "")
                 confs2.append(float(c or 0.0))
-                m = _metrics(t or "")
-                s = _score(m)
+                s, met = text_quality_score(t or "")
+                tg = int(met.get("token_groups") or 0)
+                page_audit.append({
+                    "page_no": idx_page,
+                    "chosen_mode": "ocr",
+                    "chosen_score": float(s),
+                    "embedded_score": 0.0,
+                    "ocr_score": float(s),
+                    "embedded_len": 0,
+                    "ocr_len": len(t or ""),
+                    "ocr_conf": float(c or 0.0),
+                    "token_groups": tg,
+                })
                 self.log.info(
                     f"pdf_text_source page={idx_page}/{len(images)} chosen=ocr why=no_embedded "
-                    f"ocr_score={s:.3f} ocr_nonws={int(m.get('non_ws') or 0)} ocr_bad={int(m.get('bad') or 0)} "
-                    f"ocr_conf={float(c or 0.0):.3f}"
+                    f"ocr_score={float(s):.3f} ocr_len={len(t or '')} token_groups={tg} ocr_conf={float(c or 0.0):.3f}"
                 )
             text_debug["method"] = text_method
             text_debug["ocr_conf_avg"] = float(sum(confs2) / len(confs2)) if confs2 else 0.0
             text_debug["ocr_conf_min"] = float(min(confs2)) if confs2 else 0.0
             text_debug["ocr_conf_max"] = float(max(confs2)) if confs2 else 0.0
             ocr_summary = summarize_text_quality([compute_text_quality(t) for t in texts2])
             text_debug["ocr"] = ocr_summary
+            text_debug["page_audit"] = page_audit
             self.log.info(
                 "PDF text source: ocr reason=embedded_empty dpi=%s pages=%s conf_avg=%.3f conf_min=%.3f conf_max=%.3f quality=%s",
                 dpi,
                 len(images),
@@ -219,6 +193,22 @@ class Processor:
             )
             return texts2, confs2, len(images), text_method, text_debug
 
         need_idxs = [i for i, need in enumerate(needs_ocr) if need]
         if not need_idxs:
             text_method = "embedded"
             text_debug["method"] = text_method
             for i in range(n_pages):
-                m = embedded_metrics[i]
                 s = embedded_scores[i]
+                page_audit.append({
+                    "page_no": i + 1,
+                    "chosen_mode": "embedded",
+                    "chosen_score": float(s),
+                    "embedded_score": float(s),
+                    "ocr_score": 0.0,
+                    "embedded_len": len(embedded_texts[i] or ""),
+                    "ocr_len": 0,
+                    "ocr_conf": 0.0,
+                    "token_groups": int(embedded_token_groups[i] or 0),
+                })
                 self.log.info(
                     f"pdf_text_source page={i+1}/{n_pages} chosen=embedded why=embedded_ok "
-                    f"emb_score={s:.3f} emb_nonws={int(m.get('non_ws') or 0)} emb_bad={int(m.get('bad') or 0)}"
+                    f"emb_score={s:.3f} emb_len={len(embedded_texts[i] or '')} token_groups={int(embedded_token_groups[i] or 0)}"
                 )
+            text_debug["page_audit"] = page_audit
             return out_texts, out_confs, n_pages, text_method, text_debug
 
         segments: List[Tuple[int, int]] = []
         seg_start = need_idxs[0]
@@ -255,18 +245,22 @@ class Processor:
                 ocr_text, ocr_conf = self.ocr_engine.image_to_text(img)
                 ocr_text = ocr_text or ""
                 ocr_conf_f = float(ocr_conf or 0.0)
 
-                emb_m = embedded_metrics[page_idx]
                 emb_s = embedded_scores[page_idx]
-                ocr_m = _metrics(ocr_text)
-                ocr_s = _score(ocr_m)
+                ocr_s, ocr_met = text_quality_score(ocr_text)
+                ocr_s = float(ocr_s)
+                emb_tg = int(embedded_token_groups[page_idx] or 0)
+                ocr_tg = int(ocr_met.get("token_groups") or 0)
 
                 choose_ocr = bool(ocr_s > (emb_s + score_margin))
                 if choose_ocr:
                     out_texts[page_idx] = ocr_text
                     out_confs[page_idx] = ocr_conf_f
                     chosen = "ocr"
                     why = "embedded_weak_or_worse"
+                    chosen_score = ocr_s
+                    chosen_tg = ocr_tg
                 else:
                     chosen = "embedded"
                     why = "ocr_not_better"
+                    chosen_score = float(emb_s)
+                    chosen_tg = emb_tg
 
                 selections.append(
                     {
                         "page": page_idx + 1,
@@ -281,13 +275,29 @@ class Processor:
                         "ocr_conf": ocr_conf_f,
                     }
                 )
+                page_audit.append({
+                    "page_no": page_idx + 1,
+                    "chosen_mode": chosen,
+                    "chosen_score": float(chosen_score),
+                    "embedded_score": float(emb_s),
+                    "ocr_score": float(ocr_s),
+                    "embedded_len": len(embedded_texts[page_idx] or ""),
+                    "ocr_len": len(ocr_text or ""),
+                    "ocr_conf": float(ocr_conf_f),
+                    "token_groups": int(chosen_tg),
+                })
                 self.log.info(
                     f"pdf_text_source page={page_idx+1}/{n_pages} chosen={chosen} why={why} "
-                    f"emb_score={emb_s:.3f} emb_nonws={int(emb_m.get('non_ws') or 0)} emb_bad={int(emb_m.get('bad') or 0)} "
-                    f"ocr_score={ocr_s:.3f} ocr_nonws={int(ocr_m.get('non_ws') or 0)} ocr_bad={int(ocr_m.get('bad') or 0)} "
-                    f"ocr_conf={ocr_conf_f:.3f}"
+                    f"emb_score={float(emb_s):.3f} emb_len={len(embedded_texts[page_idx] or '')} emb_tg={emb_tg} "
+                    f"ocr_score={float(ocr_s):.3f} ocr_len={len(ocr_text or '')} ocr_tg={ocr_tg} "
+                    f"ocr_conf={ocr_conf_f:.3f}"
                 )
 
         text_debug["method"] = text_method
         text_debug["selections"] = selections
+        text_debug["page_audit"] = page_audit
+        # deterministic aggregation: weighted by chosen text length
+        denom = 0.0
+        num = 0.0
+        for pa in page_audit:
+            clen = max(1, int(pa.get("embedded_len") if pa.get("chosen_mode") == "embedded" else pa.get("ocr_len") or 0))
+            denom += float(clen)
+            num += float(pa.get("chosen_score") or 0.0) * float(clen)
+        text_debug["document_text_quality"] = float(num / denom) if denom > 0 else 0.0
         return out_texts, out_confs, n_pages, text_method, text_debug
 
     def _merge_extracted_by_key(self, per_page: List[Tuple[int, Any, str, float]]) -> List[Dict[str, Any]]:
@@ -454,6 +464,7 @@ class Processor:
         per_doc_chunks: List[Dict[str, Any]] = []
         text_method: Optional[str] = None
         text_debug: Dict[str, Any] = {}
+        page_audit_map: Dict[int, Dict[str, Any]] = {}
 
         if path.suffix.lower() == ".pdf":
             page_texts, page_confs, pages, text_method, text_debug = self._ocr_pdf_pages(path, status_cb=status_cb)
@@ -462,6 +473,9 @@ class Processor:
                 page_texts = []
                 page_confs = []
                 pages = 0
+            # per-page audit returned by _ocr_pdf_pages
+            for rec in (text_debug.get("page_audit") or []):
+                page_audit_map[int(rec.get("page_no") or 0)] = dict(rec)
             per_page: List[Tuple[int, Any, str, float]] = []
             for i, t in enumerate(page_texts, start=1):
                 ex = extract_from_text(t or "")
@@ -640,6 +654,39 @@ class Processor:
                 page_from=page_from,
                 page_to=page_to,
             )
+            # Persist aggregated document text quality (if available)
+            try:
+                # default to file-level aggregation if present; still useful
+                dtq = float(text_debug.get("document_text_quality") or 0.0)
+                setattr(doc, "document_text_quality", dtq)
+                session.add(doc)
+            except Exception:
+                pass
+
+            # Persist per-page audit rows for the pages belonging to this document chunk
+            try:
+                from kajovospend.db.models import DocumentPageAudit
+                for pno in range(int(page_from), int(page_to) + 1):
+                    rec = page_audit_map.get(int(pno))
+                    if not rec:
+                        continue
+                    session.add(DocumentPageAudit(
+                        document_id=int(doc.id),
+                        file_id=int(file_record.id),
+                        page_no=int(pno),
+                        chosen_mode=str(rec.get("chosen_mode") or "embedded"),
+                        chosen_score=float(rec.get("chosen_score") or 0.0),
+                        embedded_score=float(rec.get("embedded_score") or 0.0),
+                        ocr_score=float(rec.get("ocr_score") or 0.0),
+                        embedded_len=int(rec.get("embedded_len") or 0),
+                        ocr_len=int(rec.get("ocr_len") or 0),
+                        ocr_conf=float(rec.get("ocr_conf") or 0.0),
+                        token_groups=int(rec.get("token_groups") or 0),
+                    ))
+                session.flush()
+            except Exception as e:
+                # never fail extraction due to audit insert
+                self.log.warning(f"page_audit insert failed: {e}")
             rebuild_fts_for_document(session, doc.id, extracted.full_text if hasattr(extracted, "full_text") else ocr_text)
             created_doc_ids.append(int(doc.id))
             any_requires_review = bool(any_requires_review or requires_review)
             any_processed = True
